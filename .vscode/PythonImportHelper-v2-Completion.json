[
    {
        "label": "migrations",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "AppConfig",
        "importPath": "django.apps",
        "description": "django.apps",
        "isExtraImport": true,
        "detail": "django.apps",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "detection",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "detection",
        "description": "detection",
        "detail": "detection",
        "documentation": {}
    },
    {
        "label": "detect_all",
        "importPath": "detection",
        "description": "detection",
        "isExtraImport": true,
        "detail": "detection",
        "documentation": {}
    },
    {
        "label": "text_detection",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "text_detection",
        "description": "text_detection",
        "detail": "text_detection",
        "documentation": {}
    },
    {
        "label": "text_detection",
        "importPath": "text_detection",
        "description": "text_detection",
        "isExtraImport": true,
        "detail": "text_detection",
        "documentation": {}
    },
    {
        "label": "load_text_model",
        "importPath": "text_detection",
        "description": "text_detection",
        "isExtraImport": true,
        "detail": "text_detection",
        "documentation": {}
    },
    {
        "label": "forms",
        "importPath": "django",
        "description": "django",
        "isExtraImport": true,
        "detail": "django",
        "documentation": {}
    },
    {
        "label": "TestCase",
        "importPath": "django.test",
        "description": "django.test",
        "isExtraImport": true,
        "detail": "django.test",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "include",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "JsonResponse",
        "importPath": "django.http",
        "description": "django.http",
        "isExtraImport": true,
        "detail": "django.http",
        "documentation": {}
    },
    {
        "label": "HttpResponse",
        "importPath": "django.http",
        "description": "django.http",
        "isExtraImport": true,
        "detail": "django.http",
        "documentation": {}
    },
    {
        "label": "csrf_exempt",
        "importPath": "django.views.decorators.csrf",
        "description": "django.views.decorators.csrf",
        "isExtraImport": true,
        "detail": "django.views.decorators.csrf",
        "documentation": {}
    },
    {
        "label": "extract_ingredients_from_image",
        "importPath": "ingredient_extractor.vision",
        "description": "ingredient_extractor.vision",
        "isExtraImport": true,
        "detail": "ingredient_extractor.vision",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "PIL",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL",
        "description": "PIL",
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageEnhance",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "scipy.sparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "bbox_overlaps",
        "importPath": "lib.utils.bbox",
        "description": "lib.utils.bbox",
        "isExtraImport": true,
        "detail": "lib.utils.bbox",
        "documentation": {}
    },
    {
        "label": "bbox_overlaps",
        "importPath": "lib.utils.bbox",
        "description": "lib.utils.bbox",
        "isExtraImport": true,
        "detail": "lib.utils.bbox",
        "documentation": {}
    },
    {
        "label": "bbox_overlaps",
        "importPath": "lib.utils.bbox",
        "description": "lib.utils.bbox",
        "isExtraImport": true,
        "detail": "lib.utils.bbox",
        "documentation": {}
    },
    {
        "label": "bbox_intersections",
        "importPath": "lib.utils.bbox",
        "description": "lib.utils.bbox",
        "isExtraImport": true,
        "detail": "lib.utils.bbox",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg_from_file",
        "importPath": "lib.fast_rcnn.config",
        "description": "lib.fast_rcnn.config",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "xml.etree.ElementTree",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "xml.etree.ElementTree",
        "description": "xml.etree.ElementTree",
        "detail": "xml.etree.ElementTree",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "strftime",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "localtime",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "EasyDict",
        "importPath": "easydict",
        "description": "easydict",
        "isExtraImport": true,
        "detail": "easydict",
        "documentation": {}
    },
    {
        "label": "im_list_to_blob",
        "importPath": "lib.utils.blob",
        "description": "lib.utils.blob",
        "isExtraImport": true,
        "detail": "lib.utils.blob",
        "documentation": {}
    },
    {
        "label": "prep_im_for_blob",
        "importPath": "lib.utils.blob",
        "description": "lib.utils.blob",
        "isExtraImport": true,
        "detail": "lib.utils.blob",
        "documentation": {}
    },
    {
        "label": "im_list_to_blob",
        "importPath": "lib.utils.blob",
        "description": "lib.utils.blob",
        "isExtraImport": true,
        "detail": "lib.utils.blob",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "RoIDataLayer",
        "importPath": "lib.roi_data_layer.layer",
        "description": "lib.roi_data_layer.layer",
        "isExtraImport": true,
        "detail": "lib.roi_data_layer.layer",
        "documentation": {}
    },
    {
        "label": "Timer",
        "importPath": "lib.utils.timer",
        "description": "lib.utils.timer",
        "isExtraImport": true,
        "detail": "lib.utils.timer",
        "documentation": {}
    },
    {
        "label": "roidb",
        "importPath": "lib.roi_data_layer",
        "description": "lib.roi_data_layer",
        "isExtraImport": true,
        "detail": "lib.roi_data_layer",
        "documentation": {}
    },
    {
        "label": "proposal_layer",
        "importPath": "lib.rpn_msr.proposal_layer_tf",
        "description": "lib.rpn_msr.proposal_layer_tf",
        "isExtraImport": true,
        "detail": "lib.rpn_msr.proposal_layer_tf",
        "documentation": {}
    },
    {
        "label": "proposal_layer",
        "importPath": "lib.rpn_msr.proposal_layer_tf",
        "description": "lib.rpn_msr.proposal_layer_tf",
        "isExtraImport": true,
        "detail": "lib.rpn_msr.proposal_layer_tf",
        "documentation": {}
    },
    {
        "label": "anchor_target_layer",
        "importPath": "lib.rpn_msr.anchor_target_layer_tf",
        "description": "lib.rpn_msr.anchor_target_layer_tf",
        "isExtraImport": true,
        "detail": "lib.rpn_msr.anchor_target_layer_tf",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "xml.dom.minidom",
        "description": "xml.dom.minidom",
        "isExtraImport": true,
        "detail": "xml.dom.minidom",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "get_minibatch",
        "importPath": "lib.roi_data_layer.minibatch",
        "description": "lib.roi_data_layer.minibatch",
        "isExtraImport": true,
        "detail": "lib.roi_data_layer.minibatch",
        "documentation": {}
    },
    {
        "label": "numpy.random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy.random",
        "description": "numpy.random",
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "bbox_transform",
        "importPath": "lib.fast_rcnn.bbox_transform",
        "description": "lib.fast_rcnn.bbox_transform",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.bbox_transform",
        "documentation": {}
    },
    {
        "label": "bbox_transform",
        "importPath": "lib.fast_rcnn.bbox_transform",
        "description": "lib.fast_rcnn.bbox_transform",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.bbox_transform",
        "documentation": {}
    },
    {
        "label": "bbox_transform_inv",
        "importPath": "lib.fast_rcnn.bbox_transform",
        "description": "lib.fast_rcnn.bbox_transform",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.bbox_transform",
        "documentation": {}
    },
    {
        "label": "clip_boxes",
        "importPath": "lib.fast_rcnn.bbox_transform",
        "description": "lib.fast_rcnn.bbox_transform",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.bbox_transform",
        "documentation": {}
    },
    {
        "label": "nms",
        "importPath": "lib.fast_rcnn.nms_wrapper",
        "description": "lib.fast_rcnn.nms_wrapper",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.nms_wrapper",
        "documentation": {}
    },
    {
        "label": "nms",
        "importPath": "lib.fast_rcnn.nms_wrapper",
        "description": "lib.fast_rcnn.nms_wrapper",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.nms_wrapper",
        "documentation": {}
    },
    {
        "label": "cythonize",
        "importPath": "Cython.Build",
        "description": "Cython.Build",
        "isExtraImport": true,
        "detail": "Cython.Build",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "distutils.core",
        "description": "distutils.core",
        "isExtraImport": true,
        "detail": "distutils.core",
        "documentation": {}
    },
    {
        "label": "Extension",
        "importPath": "distutils.extension",
        "description": "distutils.extension",
        "isExtraImport": true,
        "detail": "distutils.extension",
        "documentation": {}
    },
    {
        "label": "build_ext",
        "importPath": "Cython.Distutils",
        "description": "Cython.Distutils",
        "isExtraImport": true,
        "detail": "Cython.Distutils",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "text_format",
        "importPath": "google.protobuf",
        "description": "google.protobuf",
        "isExtraImport": true,
        "detail": "google.protobuf",
        "documentation": {}
    },
    {
        "label": "string_int_label_map_pb2",
        "importPath": "object_detection.protos",
        "description": "object_detection.protos",
        "isExtraImport": true,
        "detail": "object_detection.protos",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "matplotlib;",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib;",
        "description": "matplotlib;",
        "detail": "matplotlib;",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "PIL.Image",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL.Image",
        "description": "PIL.Image",
        "detail": "PIL.Image",
        "documentation": {}
    },
    {
        "label": "PIL.ImageColor",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL.ImageColor",
        "description": "PIL.ImageColor",
        "detail": "PIL.ImageColor",
        "documentation": {}
    },
    {
        "label": "PIL.ImageDraw",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL.ImageDraw",
        "description": "PIL.ImageDraw",
        "detail": "PIL.ImageDraw",
        "documentation": {}
    },
    {
        "label": "PIL.ImageFont",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL.ImageFont",
        "description": "PIL.ImageFont",
        "detail": "PIL.ImageFont",
        "documentation": {}
    },
    {
        "label": "six",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "six",
        "description": "six",
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "standard_fields",
        "importPath": "object_detection.core",
        "description": "object_detection.core",
        "isExtraImport": true,
        "detail": "object_detection.core",
        "documentation": {}
    },
    {
        "label": "tensorflow.compat.v1",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow.compat.v1",
        "description": "tensorflow.compat.v1",
        "detail": "tensorflow.compat.v1",
        "documentation": {}
    },
    {
        "label": "NutritionTableDetector",
        "importPath": "detect_table_class",
        "description": "detect_table_class",
        "isExtraImport": true,
        "detail": "detect_table_class",
        "documentation": {}
    },
    {
        "label": "crop",
        "importPath": "crop",
        "description": "crop",
        "isExtraImport": true,
        "detail": "crop",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "process",
        "description": "process",
        "isExtraImport": true,
        "detail": "process",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "regex",
        "description": "regex",
        "isExtraImport": true,
        "detail": "regex",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "nutrient_list",
        "description": "nutrient_list",
        "isExtraImport": true,
        "detail": "nutrient_list",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "nutrient_list",
        "description": "nutrient_list",
        "isExtraImport": true,
        "detail": "nutrient_list",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "spacial_map",
        "description": "spacial_map",
        "isExtraImport": true,
        "detail": "spacial_map",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "difflib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "difflib",
        "description": "difflib",
        "detail": "difflib",
        "documentation": {}
    },
    {
        "label": "fuzzydict",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fuzzydict",
        "description": "fuzzydict",
        "detail": "fuzzydict",
        "documentation": {}
    },
    {
        "label": "FuzzyDict",
        "importPath": "fuzzydict",
        "description": "fuzzydict",
        "isExtraImport": true,
        "detail": "fuzzydict",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "pytesseract",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytesseract",
        "description": "pytesseract",
        "detail": "pytesseract",
        "documentation": {}
    },
    {
        "label": "NutritionTextDetector",
        "importPath": "text_detection_class",
        "description": "text_detection_class",
        "isExtraImport": true,
        "detail": "text_detection_class",
        "documentation": {}
    },
    {
        "label": "_get_blobs",
        "importPath": "lib.fast_rcnn.test",
        "description": "lib.fast_rcnn.test",
        "isExtraImport": true,
        "detail": "lib.fast_rcnn.test",
        "documentation": {}
    },
    {
        "label": "TextDetector",
        "importPath": "lib.text_connector.detectors",
        "description": "lib.text_connector.detectors",
        "isExtraImport": true,
        "detail": "lib.text_connector.detectors",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "lib.text_connector.text_connect_cfg",
        "description": "lib.text_connector.text_connect_cfg",
        "isExtraImport": true,
        "detail": "lib.text_connector.text_connect_cfg",
        "documentation": {}
    },
    {
        "label": "gfile",
        "importPath": "tensorflow.python.platform",
        "description": "tensorflow.python.platform",
        "isExtraImport": true,
        "detail": "tensorflow.python.platform",
        "documentation": {}
    },
    {
        "label": "get_wsgi_application",
        "importPath": "django.core.wsgi",
        "description": "django.core.wsgi",
        "isExtraImport": true,
        "detail": "django.core.wsgi",
        "documentation": {}
    },
    {
        "label": "site",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "site",
        "description": "site",
        "detail": "site",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "api.migrations.0001_initial",
        "description": "api.migrations.0001_initial",
        "peekOfCode": "class Migration(migrations.Migration):\n    initial = True\n    dependencies = [\n    ]\n    operations = [\n        migrations.CreateModel(\n            name='UploadFile',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('file', models.FileField(upload_to='files/')),",
        "detail": "api.migrations.0001_initial",
        "documentation": {}
    },
    {
        "label": "ApiConfig",
        "kind": 6,
        "importPath": "api.apps",
        "description": "api.apps",
        "peekOfCode": "class ApiConfig(AppConfig):\n    name = 'api'\n    def ready(self):\n        detect.load_model()\n        text_detect.load_text_model()",
        "detail": "api.apps",
        "documentation": {}
    },
    {
        "label": "UploadFileForm",
        "kind": 6,
        "importPath": "api.forms",
        "description": "api.forms",
        "peekOfCode": "class UploadFileForm(forms.ModelForm):\n\tclass Meta:\n\t\tmodel = UploadFile\n\t\tfields = \"__all__\"",
        "detail": "api.forms",
        "documentation": {}
    },
    {
        "label": "\t\tmodel",
        "kind": 5,
        "importPath": "api.forms",
        "description": "api.forms",
        "peekOfCode": "\t\tmodel = UploadFile\n\t\tfields = \"__all__\"",
        "detail": "api.forms",
        "documentation": {}
    },
    {
        "label": "\t\tfields",
        "kind": 5,
        "importPath": "api.forms",
        "description": "api.forms",
        "peekOfCode": "\t\tfields = \"__all__\"",
        "detail": "api.forms",
        "documentation": {}
    },
    {
        "label": "UploadFile",
        "kind": 6,
        "importPath": "api.models",
        "description": "api.models",
        "peekOfCode": "class UploadFile(models.Model):\n    file = models.FileField(upload_to='files/')",
        "detail": "api.models",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "api.urls",
        "description": "api.urls",
        "peekOfCode": "urlpatterns = [\n    path('nutritionExtract/', views.nutritionExtract, name='home'),\n     path('ingredientExtract/', views.ingredientExtract, name='ingredient'),\n]",
        "detail": "api.urls",
        "documentation": {}
    },
    {
        "label": "nutritionExtract",
        "kind": 2,
        "importPath": "api.views",
        "description": "api.views",
        "peekOfCode": "def nutritionExtract(request):\n\tif request.method == 'POST':\n\t\tnew_file = UploadFile(file = request.FILES['image'])\n\t\tnew_file.save()\n\t\tname = new_file.file.name\n\t\tresponse = detect_all(name, False)\n\t\tos.remove(file_path)\n\t\tfile_path=new_file.file.path\n\t\treturn JsonResponse(response)\n@csrf_exempt\t",
        "detail": "api.views",
        "documentation": {}
    },
    {
        "label": "ingredientExtract",
        "kind": 2,
        "importPath": "api.views",
        "description": "api.views",
        "peekOfCode": "def ingredientExtract(request):\n\tif request.method == 'POST':\n\t\tnew_file = UploadFile(file = request.FILES['image'])\n\t\tnew_file.save()\n\t\t# Delete the file from the server\n\t\t# extract_ingredients_from_image(request.FILES['image'])\n\t\tname = new_file.file.name\n\t\tfile_path=new_file.file.path\n\t\twith io.open(file_path, 'rb') as img:\n\t\t\tfile_data =img.read()",
        "detail": "api.views",
        "documentation": {}
    },
    {
        "label": "\t\tnew_file",
        "kind": 5,
        "importPath": "api.views",
        "description": "api.views",
        "peekOfCode": "\t\tnew_file = UploadFile(file = request.FILES['image'])\n\t\tnew_file.save()\n\t\tname = new_file.file.name\n\t\tresponse = detect_all(name, False)\n\t\tos.remove(file_path)\n\t\tfile_path=new_file.file.path\n\t\treturn JsonResponse(response)\n@csrf_exempt\t\ndef ingredientExtract(request):\n\tif request.method == 'POST':",
        "detail": "api.views",
        "documentation": {}
    },
    {
        "label": "\t\tname",
        "kind": 5,
        "importPath": "api.views",
        "description": "api.views",
        "peekOfCode": "\t\tname = new_file.file.name\n\t\tresponse = detect_all(name, False)\n\t\tos.remove(file_path)\n\t\tfile_path=new_file.file.path\n\t\treturn JsonResponse(response)\n@csrf_exempt\t\ndef ingredientExtract(request):\n\tif request.method == 'POST':\n\t\tnew_file = UploadFile(file = request.FILES['image'])\n\t\tnew_file.save()",
        "detail": "api.views",
        "documentation": {}
    },
    {
        "label": "\t\tresponse",
        "kind": 5,
        "importPath": "api.views",
        "description": "api.views",
        "peekOfCode": "\t\tresponse = detect_all(name, False)\n\t\tos.remove(file_path)\n\t\tfile_path=new_file.file.path\n\t\treturn JsonResponse(response)\n@csrf_exempt\t\ndef ingredientExtract(request):\n\tif request.method == 'POST':\n\t\tnew_file = UploadFile(file = request.FILES['image'])\n\t\tnew_file.save()\n\t\t# Delete the file from the server",
        "detail": "api.views",
        "documentation": {}
    },
    {
        "label": "\t\tnew_file",
        "kind": 5,
        "importPath": "api.views",
        "description": "api.views",
        "peekOfCode": "\t\tnew_file = UploadFile(file = request.FILES['image'])\n\t\tnew_file.save()\n\t\t# Delete the file from the server\n\t\t# extract_ingredients_from_image(request.FILES['image'])\n\t\tname = new_file.file.name\n\t\tfile_path=new_file.file.path\n\t\twith io.open(file_path, 'rb') as img:\n\t\t\tfile_data =img.read()\n\t\t\tfile_base64 = base64.b64encode(file_data).decode('utf-8')\n            # Convert the file to base64",
        "detail": "api.views",
        "documentation": {}
    },
    {
        "label": "\t\tname",
        "kind": 5,
        "importPath": "api.views",
        "description": "api.views",
        "peekOfCode": "\t\tname = new_file.file.name\n\t\tfile_path=new_file.file.path\n\t\twith io.open(file_path, 'rb') as img:\n\t\t\tfile_data =img.read()\n\t\t\tfile_base64 = base64.b64encode(file_data).decode('utf-8')\n            # Convert the file to base64\n\t\t\tresponse = extract_ingredients_from_image(file_base64)\n\t\t\tdict={\"ingredients\":response}\n\t\t\tos.remove(file_path)\n\t\t\treturn JsonResponse(dict)",
        "detail": "api.views",
        "documentation": {}
    },
    {
        "label": "\t\t\tfile_base64",
        "kind": 5,
        "importPath": "api.views",
        "description": "api.views",
        "peekOfCode": "\t\t\tfile_base64 = base64.b64encode(file_data).decode('utf-8')\n            # Convert the file to base64\n\t\t\tresponse = extract_ingredients_from_image(file_base64)\n\t\t\tdict={\"ingredients\":response}\n\t\t\tos.remove(file_path)\n\t\t\treturn JsonResponse(dict)",
        "detail": "api.views",
        "documentation": {}
    },
    {
        "label": "\t\t\tresponse",
        "kind": 5,
        "importPath": "api.views",
        "description": "api.views",
        "peekOfCode": "\t\t\tresponse = extract_ingredients_from_image(file_base64)\n\t\t\tdict={\"ingredients\":response}\n\t\t\tos.remove(file_path)\n\t\t\treturn JsonResponse(dict)",
        "detail": "api.views",
        "documentation": {}
    },
    {
        "label": "extract_ingredients",
        "kind": 2,
        "importPath": "ingredient_extractor.vision",
        "description": "ingredient_extractor.vision",
        "peekOfCode": "def extract_ingredients(text):\n    start = text.find(\"INGREDIENTS:\")\n    if start == -1:\n        return []\n    # Find the end of the ingredients list\n    end = text.find(\".\", start)\n    # Extract the ingredients\n    ingredients_str = text[start+len(\"INGREDIENTS:\"):end]\n    ingredients = [ing.strip().replace(\"\\n\", \"\") for ing in ingredients_str.split(\",\")]\n    return ingredients",
        "detail": "ingredient_extractor.vision",
        "documentation": {}
    },
    {
        "label": "extract_ingredients_from_image",
        "kind": 2,
        "importPath": "ingredient_extractor.vision",
        "description": "ingredient_extractor.vision",
        "peekOfCode": "def extract_ingredients_from_image(content):\n    # Set up the Vision API endpoint URL\n    url = 'https://vision.googleapis.com/v1/images:annotate'\n    # Set up the API key and request headers\n    headers = {'Content-Type': 'application/json'}\n    api_key = 'AIzaSyAyyNJxYrS6QG4KpZUi91NiW1vCAFLF15c'\n    # Set up argument parser to get filename from command line input\n    # parser = argparse.ArgumentParser(description='Extract nutrition information from an image')\n    # parser.add_argument('-i', '--input', type=str, required=True, help='Input file name')\n    # args = parser.parse_args()",
        "detail": "ingredient_extractor.vision",
        "documentation": {}
    },
    {
        "label": "extract_ingredients",
        "kind": 2,
        "importPath": "ingredient_extractor.vision2",
        "description": "ingredient_extractor.vision2",
        "peekOfCode": "def extract_ingredients(text):\n    start = text.find(\"INGREDIENTS:\")\n    if start == -1:\n        return []\n    # Find the end of the ingredients list\n    end = text.find(\".\", start)\n    # Extract the ingredients\n    ingredients_str = text[start+len(\"INGREDIENTS:\"):end]\n    ingredients = [ing.strip().replace(\"\\n\", \"\") for ing in ingredients_str.split(\",\")]\n    return ingredients",
        "detail": "ingredient_extractor.vision2",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "ingredient_extractor.vision2",
        "description": "ingredient_extractor.vision2",
        "peekOfCode": "url = 'https://vision.googleapis.com/v1/images:annotate'\n# Set up the API key and request headers\nheaders = {'Content-Type': 'application/json'}\napi_key = 'AIzaSyAyyNJxYrS6QG4KpZUi91NiW1vCAFLF15c'\n# Set up argument parser to get filename from command line input\nparser = argparse.ArgumentParser(description='Extract nutrition information from an image')\nparser.add_argument('-i', '--input', type=str, required=True, help='Input file name')\nargs = parser.parse_args()\nfile_name = args.input\n# Get the directory of the current script",
        "detail": "ingredient_extractor.vision2",
        "documentation": {}
    },
    {
        "label": "headers",
        "kind": 5,
        "importPath": "ingredient_extractor.vision2",
        "description": "ingredient_extractor.vision2",
        "peekOfCode": "headers = {'Content-Type': 'application/json'}\napi_key = 'AIzaSyAyyNJxYrS6QG4KpZUi91NiW1vCAFLF15c'\n# Set up argument parser to get filename from command line input\nparser = argparse.ArgumentParser(description='Extract nutrition information from an image')\nparser.add_argument('-i', '--input', type=str, required=True, help='Input file name')\nargs = parser.parse_args()\nfile_name = args.input\n# Get the directory of the current script\ndirectory = os.path.dirname(os.path.abspath(__file__))\n# Load the image file",
        "detail": "ingredient_extractor.vision2",
        "documentation": {}
    },
    {
        "label": "api_key",
        "kind": 5,
        "importPath": "ingredient_extractor.vision2",
        "description": "ingredient_extractor.vision2",
        "peekOfCode": "api_key = 'AIzaSyAyyNJxYrS6QG4KpZUi91NiW1vCAFLF15c'\n# Set up argument parser to get filename from command line input\nparser = argparse.ArgumentParser(description='Extract nutrition information from an image')\nparser.add_argument('-i', '--input', type=str, required=True, help='Input file name')\nargs = parser.parse_args()\nfile_name = args.input\n# Get the directory of the current script\ndirectory = os.path.dirname(os.path.abspath(__file__))\n# Load the image file\nwith io.open(file_name, 'rb') as image_file:",
        "detail": "ingredient_extractor.vision2",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "ingredient_extractor.vision2",
        "description": "ingredient_extractor.vision2",
        "peekOfCode": "parser = argparse.ArgumentParser(description='Extract nutrition information from an image')\nparser.add_argument('-i', '--input', type=str, required=True, help='Input file name')\nargs = parser.parse_args()\nfile_name = args.input\n# Get the directory of the current script\ndirectory = os.path.dirname(os.path.abspath(__file__))\n# Load the image file\nwith io.open(file_name, 'rb') as image_file:\n    content = image_file.read()\n# Encode the image content as base64 string",
        "detail": "ingredient_extractor.vision2",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "ingredient_extractor.vision2",
        "description": "ingredient_extractor.vision2",
        "peekOfCode": "args = parser.parse_args()\nfile_name = args.input\n# Get the directory of the current script\ndirectory = os.path.dirname(os.path.abspath(__file__))\n# Load the image file\nwith io.open(file_name, 'rb') as image_file:\n    content = image_file.read()\n# Encode the image content as base64 string\ncontent_base64 = base64.b64encode(content).decode('utf-8')\n# Set up the request body with the image content",
        "detail": "ingredient_extractor.vision2",
        "documentation": {}
    },
    {
        "label": "file_name",
        "kind": 5,
        "importPath": "ingredient_extractor.vision2",
        "description": "ingredient_extractor.vision2",
        "peekOfCode": "file_name = args.input\n# Get the directory of the current script\ndirectory = os.path.dirname(os.path.abspath(__file__))\n# Load the image file\nwith io.open(file_name, 'rb') as image_file:\n    content = image_file.read()\n# Encode the image content as base64 string\ncontent_base64 = base64.b64encode(content).decode('utf-8')\n# Set up the request body with the image content\nrequest_body = {",
        "detail": "ingredient_extractor.vision2",
        "documentation": {}
    },
    {
        "label": "directory",
        "kind": 5,
        "importPath": "ingredient_extractor.vision2",
        "description": "ingredient_extractor.vision2",
        "peekOfCode": "directory = os.path.dirname(os.path.abspath(__file__))\n# Load the image file\nwith io.open(file_name, 'rb') as image_file:\n    content = image_file.read()\n# Encode the image content as base64 string\ncontent_base64 = base64.b64encode(content).decode('utf-8')\n# Set up the request body with the image content\nrequest_body = {\n    'requests': [{\n        'image': {",
        "detail": "ingredient_extractor.vision2",
        "documentation": {}
    },
    {
        "label": "content_base64",
        "kind": 5,
        "importPath": "ingredient_extractor.vision2",
        "description": "ingredient_extractor.vision2",
        "peekOfCode": "content_base64 = base64.b64encode(content).decode('utf-8')\n# Set up the request body with the image content\nrequest_body = {\n    'requests': [{\n        'image': {\n            'content': content_base64\n        },\n        'features': [{\n            'type': 'TEXT_DETECTION'\n        }]",
        "detail": "ingredient_extractor.vision2",
        "documentation": {}
    },
    {
        "label": "request_body",
        "kind": 5,
        "importPath": "ingredient_extractor.vision2",
        "description": "ingredient_extractor.vision2",
        "peekOfCode": "request_body = {\n    'requests': [{\n        'image': {\n            'content': content_base64\n        },\n        'features': [{\n            'type': 'TEXT_DETECTION'\n        }]\n    }]\n}",
        "detail": "ingredient_extractor.vision2",
        "documentation": {}
    },
    {
        "label": "get_imdb",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.datasets.factory",
        "description": "nutrition_extractor.lib.datasets.factory",
        "peekOfCode": "def get_imdb(name):\n    \"\"\"Get an imdb (image database) by name.\"\"\"\n    if name not in __sets:\n        print((list_imdbs()))\n        raise KeyError('Unknown dataset: {}'.format(name))\n    return __sets[name]()\ndef list_imdbs():\n    \"\"\"List all registered imdbs.\"\"\"\n    return list(__sets.keys())",
        "detail": "nutrition_extractor.lib.datasets.factory",
        "documentation": {}
    },
    {
        "label": "list_imdbs",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.datasets.factory",
        "description": "nutrition_extractor.lib.datasets.factory",
        "peekOfCode": "def list_imdbs():\n    \"\"\"List all registered imdbs.\"\"\"\n    return list(__sets.keys())",
        "detail": "nutrition_extractor.lib.datasets.factory",
        "documentation": {}
    },
    {
        "label": "__sets",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.datasets.factory",
        "description": "nutrition_extractor.lib.datasets.factory",
        "peekOfCode": "__sets = {}\ndef _selective_search_IJCV_top_k(split, year, top_k):\n    imdb = pascal_voc(split, year)\n    imdb.roidb_handler = imdb.selective_search_IJCV_roidb\n    imdb.config['top_k'] = top_k\n    return imdb\n# Set up voc_<year>_<split> using selective search \"fast\" mode\nfor year in ['2007', '2012', '0712']:\n    for split in ['train', 'val', 'trainval', 'test']:\n        name = 'voc_{}_{}'.format(year, split)",
        "detail": "nutrition_extractor.lib.datasets.factory",
        "documentation": {}
    },
    {
        "label": "imdb",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.datasets.imdb",
        "description": "nutrition_extractor.lib.datasets.imdb",
        "peekOfCode": "class imdb(object):\n    def __init__(self, name):\n        self._name = name\n        self._num_classes = 0\n        self._classes = []\n        self._image_index = []\n        self._obj_proposer = 'selective_search'\n        self._roidb = None\n        print(self.default_roidb)\n        self._roidb_handler = self.default_roidb",
        "detail": "nutrition_extractor.lib.datasets.imdb",
        "documentation": {}
    },
    {
        "label": "pascal_voc",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.datasets.pascal_voc",
        "description": "nutrition_extractor.lib.datasets.pascal_voc",
        "peekOfCode": "class pascal_voc(imdb):\n    def __init__(self, image_set, year, devkit_path=None):\n        imdb.__init__(self, 'voc_' + year + '_' + image_set)\n        self._year = year\n        self._image_set = image_set\n        self._devkit_path = self._get_default_path() if devkit_path is None \\\n                            else devkit_path\n        self._data_path = os.path.join(self._devkit_path, 'VOC' + self._year)\n        self._classes = ('__background__', # always index 0\n                         'text')",
        "detail": "nutrition_extractor.lib.datasets.pascal_voc",
        "documentation": {}
    },
    {
        "label": "bbox_transform",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.bbox_transform",
        "description": "nutrition_extractor.lib.fast_rcnn.bbox_transform",
        "peekOfCode": "def bbox_transform(ex_rois, gt_rois):\n    \"\"\"\n    computes the distance from ground-truth boxes to the given boxes, normed by their size\n    :param ex_rois: n * 4 numpy array, given boxes\n    :param gt_rois: n * 4 numpy array, ground-truth boxes\n    :return: deltas: n * 4 numpy array, ground-truth boxes\n    \"\"\"\n    ex_widths = ex_rois[:, 2] - ex_rois[:, 0] + 1.0\n    ex_heights = ex_rois[:, 3] - ex_rois[:, 1] + 1.0\n    ex_ctr_x = ex_rois[:, 0] + 0.5 * ex_widths",
        "detail": "nutrition_extractor.lib.fast_rcnn.bbox_transform",
        "documentation": {}
    },
    {
        "label": "bbox_transform_inv",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.bbox_transform",
        "description": "nutrition_extractor.lib.fast_rcnn.bbox_transform",
        "peekOfCode": "def bbox_transform_inv(boxes, deltas):\n    boxes = boxes.astype(deltas.dtype, copy=False)\n    widths = boxes[:, 2] - boxes[:, 0] + 1.0\n    heights = boxes[:, 3] - boxes[:, 1] + 1.0\n    ctr_x = boxes[:, 0] + 0.5 * widths\n    ctr_y = boxes[:, 1] + 0.5 * heights\n    dx = deltas[:, 0::4]\n    dy = deltas[:, 1::4]\n    dw = deltas[:, 2::4]\n    dh = deltas[:, 3::4]",
        "detail": "nutrition_extractor.lib.fast_rcnn.bbox_transform",
        "documentation": {}
    },
    {
        "label": "clip_boxes",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.bbox_transform",
        "description": "nutrition_extractor.lib.fast_rcnn.bbox_transform",
        "peekOfCode": "def clip_boxes(boxes, im_shape):\n    \"\"\"\n    Clip boxes to image boundaries.\n    \"\"\"\n    # x1 >= 0\n    boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)\n    # y1 >= 0\n    boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)\n    # x2 < im_shape[1]\n    boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)",
        "detail": "nutrition_extractor.lib.fast_rcnn.bbox_transform",
        "documentation": {}
    },
    {
        "label": "get_output_dir",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "def get_output_dir(imdb, weights_filename):\n    \"\"\"Return the directory where experimental artifacts are placed.\n    If the directory does not exist, it is created.\n    A canonical path is built using the name from an imdb and a network\n    (if not None).\n    \"\"\"\n    outdir = osp.abspath(osp.join(__C.ROOT_DIR, 'output', __C.EXP_DIR, imdb.name))\n    if weights_filename is not None:\n        outdir = osp.join(outdir, weights_filename)\n    if not os.path.exists(outdir):",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "get_log_dir",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "def get_log_dir(imdb):\n    \"\"\"Return the directory where experimental artifacts are placed.\n    If the directory does not exist, it is created.\n    A canonical path is built using the name from an imdb and a network\n    (if not None).\n    \"\"\"\n    log_dir = osp.abspath(\\\n        osp.join(__C.ROOT_DIR, 'logs', __C.LOG_DIR, imdb.name, strftime(\"%Y-%m-%d-%H-%M-%S\", localtime())))\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg_from_file",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "def cfg_from_file(filename):\n    \"\"\"Load a config file and merge it into the default options.\"\"\"\n    import yaml\n    with open(filename, 'r') as f:\n        yaml_cfg = edict(yaml.load(f))\n    _merge_a_into_b(yaml_cfg, __C)\ndef cfg_from_list(cfg_list):\n    \"\"\"Set config keys via list (e.g., from command line).\"\"\"\n    from ast import literal_eval\n    assert len(cfg_list) % 2 == 0",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg_from_list",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "def cfg_from_list(cfg_list):\n    \"\"\"Set config keys via list (e.g., from command line).\"\"\"\n    from ast import literal_eval\n    assert len(cfg_list) % 2 == 0\n    for k, v in zip(cfg_list[0::2], cfg_list[1::2]):\n        key_list = k.split('.')\n        d = __C\n        for subkey in key_list[:-1]:\n            assert subkey in d\n            d = d[subkey]",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C = edict()\ncfg = __C\n# Default GPU device id\n__C.GPU_ID = 0\n# Training options\n__C.IS_RPN = True\n__C.ANCHOR_SCALES = [16]\n__C.NCLASSES = 2\n__C.USE_GPU_NMS = True\n# multiscale training and testing",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "cfg = __C\n# Default GPU device id\n__C.GPU_ID = 0\n# Training options\n__C.IS_RPN = True\n__C.ANCHOR_SCALES = [16]\n__C.NCLASSES = 2\n__C.USE_GPU_NMS = True\n# multiscale training and testing\n__C.IS_MULTISCALE = False",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.GPU_ID",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.GPU_ID = 0\n# Training options\n__C.IS_RPN = True\n__C.ANCHOR_SCALES = [16]\n__C.NCLASSES = 2\n__C.USE_GPU_NMS = True\n# multiscale training and testing\n__C.IS_MULTISCALE = False\n__C.IS_EXTRAPOLATING = True\n__C.REGION_PROPOSAL = 'RPN'",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.IS_RPN",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.IS_RPN = True\n__C.ANCHOR_SCALES = [16]\n__C.NCLASSES = 2\n__C.USE_GPU_NMS = True\n# multiscale training and testing\n__C.IS_MULTISCALE = False\n__C.IS_EXTRAPOLATING = True\n__C.REGION_PROPOSAL = 'RPN'\n__C.NET_NAME = 'VGGnet'\n__C.SUBCLS_NAME = 'voxel_exemplars'",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.ANCHOR_SCALES",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.ANCHOR_SCALES = [16]\n__C.NCLASSES = 2\n__C.USE_GPU_NMS = True\n# multiscale training and testing\n__C.IS_MULTISCALE = False\n__C.IS_EXTRAPOLATING = True\n__C.REGION_PROPOSAL = 'RPN'\n__C.NET_NAME = 'VGGnet'\n__C.SUBCLS_NAME = 'voxel_exemplars'\n__C.TRAIN = edict()",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.NCLASSES",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.NCLASSES = 2\n__C.USE_GPU_NMS = True\n# multiscale training and testing\n__C.IS_MULTISCALE = False\n__C.IS_EXTRAPOLATING = True\n__C.REGION_PROPOSAL = 'RPN'\n__C.NET_NAME = 'VGGnet'\n__C.SUBCLS_NAME = 'voxel_exemplars'\n__C.TRAIN = edict()\n# Adam, Momentum, RMS",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.USE_GPU_NMS",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.USE_GPU_NMS = True\n# multiscale training and testing\n__C.IS_MULTISCALE = False\n__C.IS_EXTRAPOLATING = True\n__C.REGION_PROPOSAL = 'RPN'\n__C.NET_NAME = 'VGGnet'\n__C.SUBCLS_NAME = 'voxel_exemplars'\n__C.TRAIN = edict()\n# Adam, Momentum, RMS\n__C.TRAIN.restore = 0",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.IS_MULTISCALE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.IS_MULTISCALE = False\n__C.IS_EXTRAPOLATING = True\n__C.REGION_PROPOSAL = 'RPN'\n__C.NET_NAME = 'VGGnet'\n__C.SUBCLS_NAME = 'voxel_exemplars'\n__C.TRAIN = edict()\n# Adam, Momentum, RMS\n__C.TRAIN.restore = 0\n__C.TRAIN.max_steps = 100000\n__C.TRAIN.SOLVER = 'Momentum'",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.IS_EXTRAPOLATING",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.IS_EXTRAPOLATING = True\n__C.REGION_PROPOSAL = 'RPN'\n__C.NET_NAME = 'VGGnet'\n__C.SUBCLS_NAME = 'voxel_exemplars'\n__C.TRAIN = edict()\n# Adam, Momentum, RMS\n__C.TRAIN.restore = 0\n__C.TRAIN.max_steps = 100000\n__C.TRAIN.SOLVER = 'Momentum'\n# learning rate",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.REGION_PROPOSAL",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.REGION_PROPOSAL = 'RPN'\n__C.NET_NAME = 'VGGnet'\n__C.SUBCLS_NAME = 'voxel_exemplars'\n__C.TRAIN = edict()\n# Adam, Momentum, RMS\n__C.TRAIN.restore = 0\n__C.TRAIN.max_steps = 100000\n__C.TRAIN.SOLVER = 'Momentum'\n# learning rate\n__C.TRAIN.WEIGHT_DECAY = 0.0005",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.NET_NAME",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.NET_NAME = 'VGGnet'\n__C.SUBCLS_NAME = 'voxel_exemplars'\n__C.TRAIN = edict()\n# Adam, Momentum, RMS\n__C.TRAIN.restore = 0\n__C.TRAIN.max_steps = 100000\n__C.TRAIN.SOLVER = 'Momentum'\n# learning rate\n__C.TRAIN.WEIGHT_DECAY = 0.0005\n__C.TRAIN.LEARNING_RATE = 0.001",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.SUBCLS_NAME",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.SUBCLS_NAME = 'voxel_exemplars'\n__C.TRAIN = edict()\n# Adam, Momentum, RMS\n__C.TRAIN.restore = 0\n__C.TRAIN.max_steps = 100000\n__C.TRAIN.SOLVER = 'Momentum'\n# learning rate\n__C.TRAIN.WEIGHT_DECAY = 0.0005\n__C.TRAIN.LEARNING_RATE = 0.001\n__C.TRAIN.MOMENTUM = 0.9",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN = edict()\n# Adam, Momentum, RMS\n__C.TRAIN.restore = 0\n__C.TRAIN.max_steps = 100000\n__C.TRAIN.SOLVER = 'Momentum'\n# learning rate\n__C.TRAIN.WEIGHT_DECAY = 0.0005\n__C.TRAIN.LEARNING_RATE = 0.001\n__C.TRAIN.MOMENTUM = 0.9\n__C.TRAIN.GAMMA = 0.1",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.restore",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.restore = 0\n__C.TRAIN.max_steps = 100000\n__C.TRAIN.SOLVER = 'Momentum'\n# learning rate\n__C.TRAIN.WEIGHT_DECAY = 0.0005\n__C.TRAIN.LEARNING_RATE = 0.001\n__C.TRAIN.MOMENTUM = 0.9\n__C.TRAIN.GAMMA = 0.1\n__C.TRAIN.STEPSIZE = 50000\n__C.TRAIN.DISPLAY = 10",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.max_steps",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.max_steps = 100000\n__C.TRAIN.SOLVER = 'Momentum'\n# learning rate\n__C.TRAIN.WEIGHT_DECAY = 0.0005\n__C.TRAIN.LEARNING_RATE = 0.001\n__C.TRAIN.MOMENTUM = 0.9\n__C.TRAIN.GAMMA = 0.1\n__C.TRAIN.STEPSIZE = 50000\n__C.TRAIN.DISPLAY = 10\n__C.TRAIN.LOG_IMAGE_ITERS = 100",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.SOLVER",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.SOLVER = 'Momentum'\n# learning rate\n__C.TRAIN.WEIGHT_DECAY = 0.0005\n__C.TRAIN.LEARNING_RATE = 0.001\n__C.TRAIN.MOMENTUM = 0.9\n__C.TRAIN.GAMMA = 0.1\n__C.TRAIN.STEPSIZE = 50000\n__C.TRAIN.DISPLAY = 10\n__C.TRAIN.LOG_IMAGE_ITERS = 100\n__C.TRAIN.OHEM = False",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.WEIGHT_DECAY",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.WEIGHT_DECAY = 0.0005\n__C.TRAIN.LEARNING_RATE = 0.001\n__C.TRAIN.MOMENTUM = 0.9\n__C.TRAIN.GAMMA = 0.1\n__C.TRAIN.STEPSIZE = 50000\n__C.TRAIN.DISPLAY = 10\n__C.TRAIN.LOG_IMAGE_ITERS = 100\n__C.TRAIN.OHEM = False\n__C.TRAIN.RANDOM_DOWNSAMPLE = False\n# Scales to compute real features",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.LEARNING_RATE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.LEARNING_RATE = 0.001\n__C.TRAIN.MOMENTUM = 0.9\n__C.TRAIN.GAMMA = 0.1\n__C.TRAIN.STEPSIZE = 50000\n__C.TRAIN.DISPLAY = 10\n__C.TRAIN.LOG_IMAGE_ITERS = 100\n__C.TRAIN.OHEM = False\n__C.TRAIN.RANDOM_DOWNSAMPLE = False\n# Scales to compute real features\n__C.TRAIN.SCALES_BASE = (0.25, 0.5, 1.0, 2.0, 3.0)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.MOMENTUM",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.MOMENTUM = 0.9\n__C.TRAIN.GAMMA = 0.1\n__C.TRAIN.STEPSIZE = 50000\n__C.TRAIN.DISPLAY = 10\n__C.TRAIN.LOG_IMAGE_ITERS = 100\n__C.TRAIN.OHEM = False\n__C.TRAIN.RANDOM_DOWNSAMPLE = False\n# Scales to compute real features\n__C.TRAIN.SCALES_BASE = (0.25, 0.5, 1.0, 2.0, 3.0)\n__C.TRAIN.KERNEL_SIZE = 5",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.GAMMA",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.GAMMA = 0.1\n__C.TRAIN.STEPSIZE = 50000\n__C.TRAIN.DISPLAY = 10\n__C.TRAIN.LOG_IMAGE_ITERS = 100\n__C.TRAIN.OHEM = False\n__C.TRAIN.RANDOM_DOWNSAMPLE = False\n# Scales to compute real features\n__C.TRAIN.SCALES_BASE = (0.25, 0.5, 1.0, 2.0, 3.0)\n__C.TRAIN.KERNEL_SIZE = 5\n__C.TRAIN.ASPECTS= (1,)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.STEPSIZE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.STEPSIZE = 50000\n__C.TRAIN.DISPLAY = 10\n__C.TRAIN.LOG_IMAGE_ITERS = 100\n__C.TRAIN.OHEM = False\n__C.TRAIN.RANDOM_DOWNSAMPLE = False\n# Scales to compute real features\n__C.TRAIN.SCALES_BASE = (0.25, 0.5, 1.0, 2.0, 3.0)\n__C.TRAIN.KERNEL_SIZE = 5\n__C.TRAIN.ASPECTS= (1,)\n__C.TRAIN.SCALES = (600,)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.DISPLAY",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.DISPLAY = 10\n__C.TRAIN.LOG_IMAGE_ITERS = 100\n__C.TRAIN.OHEM = False\n__C.TRAIN.RANDOM_DOWNSAMPLE = False\n# Scales to compute real features\n__C.TRAIN.SCALES_BASE = (0.25, 0.5, 1.0, 2.0, 3.0)\n__C.TRAIN.KERNEL_SIZE = 5\n__C.TRAIN.ASPECTS= (1,)\n__C.TRAIN.SCALES = (600,)\n# Max pixel size of the longest side of a scaled input image",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.LOG_IMAGE_ITERS",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.LOG_IMAGE_ITERS = 100\n__C.TRAIN.OHEM = False\n__C.TRAIN.RANDOM_DOWNSAMPLE = False\n# Scales to compute real features\n__C.TRAIN.SCALES_BASE = (0.25, 0.5, 1.0, 2.0, 3.0)\n__C.TRAIN.KERNEL_SIZE = 5\n__C.TRAIN.ASPECTS= (1,)\n__C.TRAIN.SCALES = (600,)\n# Max pixel size of the longest side of a scaled input image\n__C.TRAIN.MAX_SIZE = 1000",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.OHEM",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.OHEM = False\n__C.TRAIN.RANDOM_DOWNSAMPLE = False\n# Scales to compute real features\n__C.TRAIN.SCALES_BASE = (0.25, 0.5, 1.0, 2.0, 3.0)\n__C.TRAIN.KERNEL_SIZE = 5\n__C.TRAIN.ASPECTS= (1,)\n__C.TRAIN.SCALES = (600,)\n# Max pixel size of the longest side of a scaled input image\n__C.TRAIN.MAX_SIZE = 1000\n# Images to use per minibatch",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.RANDOM_DOWNSAMPLE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.RANDOM_DOWNSAMPLE = False\n# Scales to compute real features\n__C.TRAIN.SCALES_BASE = (0.25, 0.5, 1.0, 2.0, 3.0)\n__C.TRAIN.KERNEL_SIZE = 5\n__C.TRAIN.ASPECTS= (1,)\n__C.TRAIN.SCALES = (600,)\n# Max pixel size of the longest side of a scaled input image\n__C.TRAIN.MAX_SIZE = 1000\n# Images to use per minibatch\n__C.TRAIN.IMS_PER_BATCH = 2",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.SCALES_BASE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.SCALES_BASE = (0.25, 0.5, 1.0, 2.0, 3.0)\n__C.TRAIN.KERNEL_SIZE = 5\n__C.TRAIN.ASPECTS= (1,)\n__C.TRAIN.SCALES = (600,)\n# Max pixel size of the longest side of a scaled input image\n__C.TRAIN.MAX_SIZE = 1000\n# Images to use per minibatch\n__C.TRAIN.IMS_PER_BATCH = 2\n# Minibatch size (number of regions of interest [ROIs])\n__C.TRAIN.BATCH_SIZE = 128",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.KERNEL_SIZE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.KERNEL_SIZE = 5\n__C.TRAIN.ASPECTS= (1,)\n__C.TRAIN.SCALES = (600,)\n# Max pixel size of the longest side of a scaled input image\n__C.TRAIN.MAX_SIZE = 1000\n# Images to use per minibatch\n__C.TRAIN.IMS_PER_BATCH = 2\n# Minibatch size (number of regions of interest [ROIs])\n__C.TRAIN.BATCH_SIZE = 128\n# Fraction of minibatch that is labeled foreground (i.e. class > 0)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.SCALES",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.SCALES = (600,)\n# Max pixel size of the longest side of a scaled input image\n__C.TRAIN.MAX_SIZE = 1000\n# Images to use per minibatch\n__C.TRAIN.IMS_PER_BATCH = 2\n# Minibatch size (number of regions of interest [ROIs])\n__C.TRAIN.BATCH_SIZE = 128\n# Fraction of minibatch that is labeled foreground (i.e. class > 0)\n__C.TRAIN.FG_FRACTION = 0.25\n# Overlap threshold for a ROI to be considered foreground (if >= FG_THRESH)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.MAX_SIZE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.MAX_SIZE = 1000\n# Images to use per minibatch\n__C.TRAIN.IMS_PER_BATCH = 2\n# Minibatch size (number of regions of interest [ROIs])\n__C.TRAIN.BATCH_SIZE = 128\n# Fraction of minibatch that is labeled foreground (i.e. class > 0)\n__C.TRAIN.FG_FRACTION = 0.25\n# Overlap threshold for a ROI to be considered foreground (if >= FG_THRESH)\n__C.TRAIN.FG_THRESH = 0.5\n# Overlap threshold for a ROI to be considered background (class = 0 if",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.IMS_PER_BATCH",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.IMS_PER_BATCH = 2\n# Minibatch size (number of regions of interest [ROIs])\n__C.TRAIN.BATCH_SIZE = 128\n# Fraction of minibatch that is labeled foreground (i.e. class > 0)\n__C.TRAIN.FG_FRACTION = 0.25\n# Overlap threshold for a ROI to be considered foreground (if >= FG_THRESH)\n__C.TRAIN.FG_THRESH = 0.5\n# Overlap threshold for a ROI to be considered background (class = 0 if\n# overlap in [LO, HI))\n__C.TRAIN.BG_THRESH_HI = 0.5",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.BATCH_SIZE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.BATCH_SIZE = 128\n# Fraction of minibatch that is labeled foreground (i.e. class > 0)\n__C.TRAIN.FG_FRACTION = 0.25\n# Overlap threshold for a ROI to be considered foreground (if >= FG_THRESH)\n__C.TRAIN.FG_THRESH = 0.5\n# Overlap threshold for a ROI to be considered background (class = 0 if\n# overlap in [LO, HI))\n__C.TRAIN.BG_THRESH_HI = 0.5\n__C.TRAIN.BG_THRESH_LO = 0.1\n# Use horizontally-flipped images during training?",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.FG_FRACTION",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.FG_FRACTION = 0.25\n# Overlap threshold for a ROI to be considered foreground (if >= FG_THRESH)\n__C.TRAIN.FG_THRESH = 0.5\n# Overlap threshold for a ROI to be considered background (class = 0 if\n# overlap in [LO, HI))\n__C.TRAIN.BG_THRESH_HI = 0.5\n__C.TRAIN.BG_THRESH_LO = 0.1\n# Use horizontally-flipped images during training?\n__C.TRAIN.USE_FLIPPED = True\n# Train bounding-box regressors",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.FG_THRESH",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.FG_THRESH = 0.5\n# Overlap threshold for a ROI to be considered background (class = 0 if\n# overlap in [LO, HI))\n__C.TRAIN.BG_THRESH_HI = 0.5\n__C.TRAIN.BG_THRESH_LO = 0.1\n# Use horizontally-flipped images during training?\n__C.TRAIN.USE_FLIPPED = True\n# Train bounding-box regressors\n__C.TRAIN.BBOX_REG = True\n# Overlap required between a ROI and ground-truth box in order for that ROI to",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.BG_THRESH_HI",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.BG_THRESH_HI = 0.5\n__C.TRAIN.BG_THRESH_LO = 0.1\n# Use horizontally-flipped images during training?\n__C.TRAIN.USE_FLIPPED = True\n# Train bounding-box regressors\n__C.TRAIN.BBOX_REG = True\n# Overlap required between a ROI and ground-truth box in order for that ROI to\n# be used as a bounding-box regression training example\n__C.TRAIN.BBOX_THRESH = 0.5\n# Iterations between snapshots",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.BG_THRESH_LO",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.BG_THRESH_LO = 0.1\n# Use horizontally-flipped images during training?\n__C.TRAIN.USE_FLIPPED = True\n# Train bounding-box regressors\n__C.TRAIN.BBOX_REG = True\n# Overlap required between a ROI and ground-truth box in order for that ROI to\n# be used as a bounding-box regression training example\n__C.TRAIN.BBOX_THRESH = 0.5\n# Iterations between snapshots\n__C.TRAIN.SNAPSHOT_ITERS = 5000",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.USE_FLIPPED",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.USE_FLIPPED = True\n# Train bounding-box regressors\n__C.TRAIN.BBOX_REG = True\n# Overlap required between a ROI and ground-truth box in order for that ROI to\n# be used as a bounding-box regression training example\n__C.TRAIN.BBOX_THRESH = 0.5\n# Iterations between snapshots\n__C.TRAIN.SNAPSHOT_ITERS = 5000\n# solver.prototxt specifies the snapshot path prefix, this adds an optional\n# infix to yield the path: <prefix>[_<infix>]_iters_XYZ.caffemodel",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.BBOX_REG",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.BBOX_REG = True\n# Overlap required between a ROI and ground-truth box in order for that ROI to\n# be used as a bounding-box regression training example\n__C.TRAIN.BBOX_THRESH = 0.5\n# Iterations between snapshots\n__C.TRAIN.SNAPSHOT_ITERS = 5000\n# solver.prototxt specifies the snapshot path prefix, this adds an optional\n# infix to yield the path: <prefix>[_<infix>]_iters_XYZ.caffemodel\n__C.TRAIN.SNAPSHOT_PREFIX = 'VGGnet_fast_rcnn'\n__C.TRAIN.SNAPSHOT_INFIX = ''",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.BBOX_THRESH",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.BBOX_THRESH = 0.5\n# Iterations between snapshots\n__C.TRAIN.SNAPSHOT_ITERS = 5000\n# solver.prototxt specifies the snapshot path prefix, this adds an optional\n# infix to yield the path: <prefix>[_<infix>]_iters_XYZ.caffemodel\n__C.TRAIN.SNAPSHOT_PREFIX = 'VGGnet_fast_rcnn'\n__C.TRAIN.SNAPSHOT_INFIX = ''\n# Use a prefetch thread in roi_data_layer.layer\n# So far I haven't found this useful; likely more engineering work is required\n__C.TRAIN.USE_PREFETCH = False",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.SNAPSHOT_ITERS",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.SNAPSHOT_ITERS = 5000\n# solver.prototxt specifies the snapshot path prefix, this adds an optional\n# infix to yield the path: <prefix>[_<infix>]_iters_XYZ.caffemodel\n__C.TRAIN.SNAPSHOT_PREFIX = 'VGGnet_fast_rcnn'\n__C.TRAIN.SNAPSHOT_INFIX = ''\n# Use a prefetch thread in roi_data_layer.layer\n# So far I haven't found this useful; likely more engineering work is required\n__C.TRAIN.USE_PREFETCH = False\n# Normalize the targets (subtract empirical mean, divide by empirical stddev)\n__C.TRAIN.BBOX_NORMALIZE_TARGETS = True",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.SNAPSHOT_PREFIX",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.SNAPSHOT_PREFIX = 'VGGnet_fast_rcnn'\n__C.TRAIN.SNAPSHOT_INFIX = ''\n# Use a prefetch thread in roi_data_layer.layer\n# So far I haven't found this useful; likely more engineering work is required\n__C.TRAIN.USE_PREFETCH = False\n# Normalize the targets (subtract empirical mean, divide by empirical stddev)\n__C.TRAIN.BBOX_NORMALIZE_TARGETS = True\n# Deprecated (inside weights)\n# used for assigning weights for each coords (x1, y1, w, h)\n__C.TRAIN.BBOX_INSIDE_WEIGHTS = (1.0, 1.0, 1.0, 1.0)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.SNAPSHOT_INFIX",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.SNAPSHOT_INFIX = ''\n# Use a prefetch thread in roi_data_layer.layer\n# So far I haven't found this useful; likely more engineering work is required\n__C.TRAIN.USE_PREFETCH = False\n# Normalize the targets (subtract empirical mean, divide by empirical stddev)\n__C.TRAIN.BBOX_NORMALIZE_TARGETS = True\n# Deprecated (inside weights)\n# used for assigning weights for each coords (x1, y1, w, h)\n__C.TRAIN.BBOX_INSIDE_WEIGHTS = (1.0, 1.0, 1.0, 1.0)\n# Normalize the targets using \"precomputed\" (or made up) means and stdevs",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.USE_PREFETCH",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.USE_PREFETCH = False\n# Normalize the targets (subtract empirical mean, divide by empirical stddev)\n__C.TRAIN.BBOX_NORMALIZE_TARGETS = True\n# Deprecated (inside weights)\n# used for assigning weights for each coords (x1, y1, w, h)\n__C.TRAIN.BBOX_INSIDE_WEIGHTS = (1.0, 1.0, 1.0, 1.0)\n# Normalize the targets using \"precomputed\" (or made up) means and stdevs\n# (BBOX_NORMALIZE_TARGETS must also be True)\n__C.TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED = True\n__C.TRAIN.BBOX_NORMALIZE_MEANS = (0.0, 0.0, 0.0, 0.0)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.BBOX_NORMALIZE_TARGETS",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.BBOX_NORMALIZE_TARGETS = True\n# Deprecated (inside weights)\n# used for assigning weights for each coords (x1, y1, w, h)\n__C.TRAIN.BBOX_INSIDE_WEIGHTS = (1.0, 1.0, 1.0, 1.0)\n# Normalize the targets using \"precomputed\" (or made up) means and stdevs\n# (BBOX_NORMALIZE_TARGETS must also be True)\n__C.TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED = True\n__C.TRAIN.BBOX_NORMALIZE_MEANS = (0.0, 0.0, 0.0, 0.0)\n__C.TRAIN.BBOX_NORMALIZE_STDS = (0.1, 0.1, 0.2, 0.2)\n# faster rcnn dont use pre-generated rois by selective search",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.BBOX_INSIDE_WEIGHTS",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.BBOX_INSIDE_WEIGHTS = (1.0, 1.0, 1.0, 1.0)\n# Normalize the targets using \"precomputed\" (or made up) means and stdevs\n# (BBOX_NORMALIZE_TARGETS must also be True)\n__C.TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED = True\n__C.TRAIN.BBOX_NORMALIZE_MEANS = (0.0, 0.0, 0.0, 0.0)\n__C.TRAIN.BBOX_NORMALIZE_STDS = (0.1, 0.1, 0.2, 0.2)\n# faster rcnn dont use pre-generated rois by selective search\n# __C.TRAIN.BBOX_NORMALIZE_STDS = (1, 1, 1, 1)\n# Train using these proposals\n__C.TRAIN.PROPOSAL_METHOD = 'selective_search'",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED = True\n__C.TRAIN.BBOX_NORMALIZE_MEANS = (0.0, 0.0, 0.0, 0.0)\n__C.TRAIN.BBOX_NORMALIZE_STDS = (0.1, 0.1, 0.2, 0.2)\n# faster rcnn dont use pre-generated rois by selective search\n# __C.TRAIN.BBOX_NORMALIZE_STDS = (1, 1, 1, 1)\n# Train using these proposals\n__C.TRAIN.PROPOSAL_METHOD = 'selective_search'\n# Make minibatches from images that have similar aspect ratios (i.e. both\n# tall and thin or both short and wide) in order to avoid wasting computation\n# on zero-padding.",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.BBOX_NORMALIZE_MEANS",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.BBOX_NORMALIZE_MEANS = (0.0, 0.0, 0.0, 0.0)\n__C.TRAIN.BBOX_NORMALIZE_STDS = (0.1, 0.1, 0.2, 0.2)\n# faster rcnn dont use pre-generated rois by selective search\n# __C.TRAIN.BBOX_NORMALIZE_STDS = (1, 1, 1, 1)\n# Train using these proposals\n__C.TRAIN.PROPOSAL_METHOD = 'selective_search'\n# Make minibatches from images that have similar aspect ratios (i.e. both\n# tall and thin or both short and wide) in order to avoid wasting computation\n# on zero-padding.\n__C.TRAIN.ASPECT_GROUPING = True",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.BBOX_NORMALIZE_STDS",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.BBOX_NORMALIZE_STDS = (0.1, 0.1, 0.2, 0.2)\n# faster rcnn dont use pre-generated rois by selective search\n# __C.TRAIN.BBOX_NORMALIZE_STDS = (1, 1, 1, 1)\n# Train using these proposals\n__C.TRAIN.PROPOSAL_METHOD = 'selective_search'\n# Make minibatches from images that have similar aspect ratios (i.e. both\n# tall and thin or both short and wide) in order to avoid wasting computation\n# on zero-padding.\n__C.TRAIN.ASPECT_GROUPING = True\n# preclude rois intersected with dontcare areas above the value",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.PROPOSAL_METHOD",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.PROPOSAL_METHOD = 'selective_search'\n# Make minibatches from images that have similar aspect ratios (i.e. both\n# tall and thin or both short and wide) in order to avoid wasting computation\n# on zero-padding.\n__C.TRAIN.ASPECT_GROUPING = True\n# preclude rois intersected with dontcare areas above the value\n__C.TRAIN.DONTCARE_AREA_INTERSECTION_HI = 0.5\n__C.TRAIN.PRECLUDE_HARD_SAMPLES = True\n# Use RPN to detect objects\n__C.TRAIN.HAS_RPN = True",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.ASPECT_GROUPING",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.ASPECT_GROUPING = True\n# preclude rois intersected with dontcare areas above the value\n__C.TRAIN.DONTCARE_AREA_INTERSECTION_HI = 0.5\n__C.TRAIN.PRECLUDE_HARD_SAMPLES = True\n# Use RPN to detect objects\n__C.TRAIN.HAS_RPN = True\n# IOU >= thresh: positive example\n__C.TRAIN.RPN_POSITIVE_OVERLAP = 0.7\n# IOU < thresh: negative example\n__C.TRAIN.RPN_NEGATIVE_OVERLAP = 0.3",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.DONTCARE_AREA_INTERSECTION_HI",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.DONTCARE_AREA_INTERSECTION_HI = 0.5\n__C.TRAIN.PRECLUDE_HARD_SAMPLES = True\n# Use RPN to detect objects\n__C.TRAIN.HAS_RPN = True\n# IOU >= thresh: positive example\n__C.TRAIN.RPN_POSITIVE_OVERLAP = 0.7\n# IOU < thresh: negative example\n__C.TRAIN.RPN_NEGATIVE_OVERLAP = 0.3\n# If an anchor statisfied by positive and negative conditions set to negative\n__C.TRAIN.RPN_CLOBBER_POSITIVES = False",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.PRECLUDE_HARD_SAMPLES",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.PRECLUDE_HARD_SAMPLES = True\n# Use RPN to detect objects\n__C.TRAIN.HAS_RPN = True\n# IOU >= thresh: positive example\n__C.TRAIN.RPN_POSITIVE_OVERLAP = 0.7\n# IOU < thresh: negative example\n__C.TRAIN.RPN_NEGATIVE_OVERLAP = 0.3\n# If an anchor statisfied by positive and negative conditions set to negative\n__C.TRAIN.RPN_CLOBBER_POSITIVES = False\n# Max number of foreground examples",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.HAS_RPN",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.HAS_RPN = True\n# IOU >= thresh: positive example\n__C.TRAIN.RPN_POSITIVE_OVERLAP = 0.7\n# IOU < thresh: negative example\n__C.TRAIN.RPN_NEGATIVE_OVERLAP = 0.3\n# If an anchor statisfied by positive and negative conditions set to negative\n__C.TRAIN.RPN_CLOBBER_POSITIVES = False\n# Max number of foreground examples\n__C.TRAIN.RPN_FG_FRACTION = 0.5\n# Total number of examples",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.RPN_POSITIVE_OVERLAP",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.RPN_POSITIVE_OVERLAP = 0.7\n# IOU < thresh: negative example\n__C.TRAIN.RPN_NEGATIVE_OVERLAP = 0.3\n# If an anchor statisfied by positive and negative conditions set to negative\n__C.TRAIN.RPN_CLOBBER_POSITIVES = False\n# Max number of foreground examples\n__C.TRAIN.RPN_FG_FRACTION = 0.5\n# Total number of examples\n__C.TRAIN.RPN_BATCHSIZE = 256\n# NMS threshold used on RPN proposals",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.RPN_NEGATIVE_OVERLAP",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.RPN_NEGATIVE_OVERLAP = 0.3\n# If an anchor statisfied by positive and negative conditions set to negative\n__C.TRAIN.RPN_CLOBBER_POSITIVES = False\n# Max number of foreground examples\n__C.TRAIN.RPN_FG_FRACTION = 0.5\n# Total number of examples\n__C.TRAIN.RPN_BATCHSIZE = 256\n# NMS threshold used on RPN proposals\n__C.TRAIN.RPN_NMS_THRESH = 0.7\n# Number of top scoring boxes to keep before apply NMS to RPN proposals",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.RPN_CLOBBER_POSITIVES",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.RPN_CLOBBER_POSITIVES = False\n# Max number of foreground examples\n__C.TRAIN.RPN_FG_FRACTION = 0.5\n# Total number of examples\n__C.TRAIN.RPN_BATCHSIZE = 256\n# NMS threshold used on RPN proposals\n__C.TRAIN.RPN_NMS_THRESH = 0.7\n# Number of top scoring boxes to keep before apply NMS to RPN proposals\n__C.TRAIN.RPN_PRE_NMS_TOP_N = 12000\n# Number of top scoring boxes to keep after applying NMS to RPN proposals",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.RPN_FG_FRACTION",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.RPN_FG_FRACTION = 0.5\n# Total number of examples\n__C.TRAIN.RPN_BATCHSIZE = 256\n# NMS threshold used on RPN proposals\n__C.TRAIN.RPN_NMS_THRESH = 0.7\n# Number of top scoring boxes to keep before apply NMS to RPN proposals\n__C.TRAIN.RPN_PRE_NMS_TOP_N = 12000\n# Number of top scoring boxes to keep after applying NMS to RPN proposals\n__C.TRAIN.RPN_POST_NMS_TOP_N = 2000\n# Proposal height and width both need to be greater than RPN_MIN_SIZE (at orig image scale)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.RPN_BATCHSIZE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.RPN_BATCHSIZE = 256\n# NMS threshold used on RPN proposals\n__C.TRAIN.RPN_NMS_THRESH = 0.7\n# Number of top scoring boxes to keep before apply NMS to RPN proposals\n__C.TRAIN.RPN_PRE_NMS_TOP_N = 12000\n# Number of top scoring boxes to keep after applying NMS to RPN proposals\n__C.TRAIN.RPN_POST_NMS_TOP_N = 2000\n# Proposal height and width both need to be greater than RPN_MIN_SIZE (at orig image scale)\n__C.TRAIN.RPN_MIN_SIZE = 8\n# Deprecated (outside weights)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.RPN_NMS_THRESH",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.RPN_NMS_THRESH = 0.7\n# Number of top scoring boxes to keep before apply NMS to RPN proposals\n__C.TRAIN.RPN_PRE_NMS_TOP_N = 12000\n# Number of top scoring boxes to keep after applying NMS to RPN proposals\n__C.TRAIN.RPN_POST_NMS_TOP_N = 2000\n# Proposal height and width both need to be greater than RPN_MIN_SIZE (at orig image scale)\n__C.TRAIN.RPN_MIN_SIZE = 8\n# Deprecated (outside weights)\n__C.TRAIN.RPN_BBOX_INSIDE_WEIGHTS = (1.0, 1.0, 1.0, 1.0)\n# Give the positive RPN examples weight of p * 1 / {num positives}",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.RPN_PRE_NMS_TOP_N",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.RPN_PRE_NMS_TOP_N = 12000\n# Number of top scoring boxes to keep after applying NMS to RPN proposals\n__C.TRAIN.RPN_POST_NMS_TOP_N = 2000\n# Proposal height and width both need to be greater than RPN_MIN_SIZE (at orig image scale)\n__C.TRAIN.RPN_MIN_SIZE = 8\n# Deprecated (outside weights)\n__C.TRAIN.RPN_BBOX_INSIDE_WEIGHTS = (1.0, 1.0, 1.0, 1.0)\n# Give the positive RPN examples weight of p * 1 / {num positives}\n# and give negatives a weight of (1 - p)\n# Set to -1.0 to use uniform example weighting",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.RPN_POST_NMS_TOP_N",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.RPN_POST_NMS_TOP_N = 2000\n# Proposal height and width both need to be greater than RPN_MIN_SIZE (at orig image scale)\n__C.TRAIN.RPN_MIN_SIZE = 8\n# Deprecated (outside weights)\n__C.TRAIN.RPN_BBOX_INSIDE_WEIGHTS = (1.0, 1.0, 1.0, 1.0)\n# Give the positive RPN examples weight of p * 1 / {num positives}\n# and give negatives a weight of (1 - p)\n# Set to -1.0 to use uniform example weighting\n__C.TRAIN.RPN_POSITIVE_WEIGHT = -1.0\n# __C.TRAIN.RPN_POSITIVE_WEIGHT = 0.5",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.RPN_MIN_SIZE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.RPN_MIN_SIZE = 8\n# Deprecated (outside weights)\n__C.TRAIN.RPN_BBOX_INSIDE_WEIGHTS = (1.0, 1.0, 1.0, 1.0)\n# Give the positive RPN examples weight of p * 1 / {num positives}\n# and give negatives a weight of (1 - p)\n# Set to -1.0 to use uniform example weighting\n__C.TRAIN.RPN_POSITIVE_WEIGHT = -1.0\n# __C.TRAIN.RPN_POSITIVE_WEIGHT = 0.5\n#\n# Testing options",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.RPN_BBOX_INSIDE_WEIGHTS",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.RPN_BBOX_INSIDE_WEIGHTS = (1.0, 1.0, 1.0, 1.0)\n# Give the positive RPN examples weight of p * 1 / {num positives}\n# and give negatives a weight of (1 - p)\n# Set to -1.0 to use uniform example weighting\n__C.TRAIN.RPN_POSITIVE_WEIGHT = -1.0\n# __C.TRAIN.RPN_POSITIVE_WEIGHT = 0.5\n#\n# Testing options\n#\n__C.TEST = edict()",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TRAIN.RPN_POSITIVE_WEIGHT",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TRAIN.RPN_POSITIVE_WEIGHT = -1.0\n# __C.TRAIN.RPN_POSITIVE_WEIGHT = 0.5\n#\n# Testing options\n#\n__C.TEST = edict()\n__C.TEST.checkpoints_path = \"checkpoints/\"\n__C.TEST.DETECT_MODE = \"H\"#H/O for horizontal/oriented mode\n# Scales to use during testing (can list multiple scales)\n# Each scale is the pixel size of an image's shortest side",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST = edict()\n__C.TEST.checkpoints_path = \"checkpoints/\"\n__C.TEST.DETECT_MODE = \"H\"#H/O for horizontal/oriented mode\n# Scales to use during testing (can list multiple scales)\n# Each scale is the pixel size of an image's shortest side\n__C.TEST.SCALES = (600,)\n# Max pixel size of the longest side of a scaled input image\n__C.TEST.MAX_SIZE = 1000\n# Overlap threshold used for non-maximum suppression (suppress boxes with\n# IoU >= this threshold)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.checkpoints_path",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.checkpoints_path = \"checkpoints/\"\n__C.TEST.DETECT_MODE = \"H\"#H/O for horizontal/oriented mode\n# Scales to use during testing (can list multiple scales)\n# Each scale is the pixel size of an image's shortest side\n__C.TEST.SCALES = (600,)\n# Max pixel size of the longest side of a scaled input image\n__C.TEST.MAX_SIZE = 1000\n# Overlap threshold used for non-maximum suppression (suppress boxes with\n# IoU >= this threshold)\n__C.TEST.NMS = 0.3",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.DETECT_MODE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.DETECT_MODE = \"H\"#H/O for horizontal/oriented mode\n# Scales to use during testing (can list multiple scales)\n# Each scale is the pixel size of an image's shortest side\n__C.TEST.SCALES = (600,)\n# Max pixel size of the longest side of a scaled input image\n__C.TEST.MAX_SIZE = 1000\n# Overlap threshold used for non-maximum suppression (suppress boxes with\n# IoU >= this threshold)\n__C.TEST.NMS = 0.3\n# Experimental: treat the (K+1) units in the cls_score layer as linear",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.SCALES",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.SCALES = (600,)\n# Max pixel size of the longest side of a scaled input image\n__C.TEST.MAX_SIZE = 1000\n# Overlap threshold used for non-maximum suppression (suppress boxes with\n# IoU >= this threshold)\n__C.TEST.NMS = 0.3\n# Experimental: treat the (K+1) units in the cls_score layer as linear\n# predictors (trained, eg, with one-vs-rest SVMs).\n__C.TEST.SVM = False\n# Test using bounding-box regressors",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.MAX_SIZE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.MAX_SIZE = 1000\n# Overlap threshold used for non-maximum suppression (suppress boxes with\n# IoU >= this threshold)\n__C.TEST.NMS = 0.3\n# Experimental: treat the (K+1) units in the cls_score layer as linear\n# predictors (trained, eg, with one-vs-rest SVMs).\n__C.TEST.SVM = False\n# Test using bounding-box regressors\n__C.TEST.BBOX_REG = True\n# Propose boxes",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.NMS",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.NMS = 0.3\n# Experimental: treat the (K+1) units in the cls_score layer as linear\n# predictors (trained, eg, with one-vs-rest SVMs).\n__C.TEST.SVM = False\n# Test using bounding-box regressors\n__C.TEST.BBOX_REG = True\n# Propose boxes\n__C.TEST.HAS_RPN = True\n# Test using these proposals\n__C.TEST.PROPOSAL_METHOD = 'selective_search'",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.SVM",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.SVM = False\n# Test using bounding-box regressors\n__C.TEST.BBOX_REG = True\n# Propose boxes\n__C.TEST.HAS_RPN = True\n# Test using these proposals\n__C.TEST.PROPOSAL_METHOD = 'selective_search'\n## NMS threshold used on RPN proposals\n__C.TEST.RPN_NMS_THRESH = 0.7\n## Number of top scoring boxes to keep before apply NMS to RPN proposals",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.BBOX_REG",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.BBOX_REG = True\n# Propose boxes\n__C.TEST.HAS_RPN = True\n# Test using these proposals\n__C.TEST.PROPOSAL_METHOD = 'selective_search'\n## NMS threshold used on RPN proposals\n__C.TEST.RPN_NMS_THRESH = 0.7\n## Number of top scoring boxes to keep before apply NMS to RPN proposals\n#__C.TEST.RPN_PRE_NMS_TOP_N = 6000\n__C.TEST.RPN_PRE_NMS_TOP_N = 12000",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.HAS_RPN",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.HAS_RPN = True\n# Test using these proposals\n__C.TEST.PROPOSAL_METHOD = 'selective_search'\n## NMS threshold used on RPN proposals\n__C.TEST.RPN_NMS_THRESH = 0.7\n## Number of top scoring boxes to keep before apply NMS to RPN proposals\n#__C.TEST.RPN_PRE_NMS_TOP_N = 6000\n__C.TEST.RPN_PRE_NMS_TOP_N = 12000\n## Number of top scoring boxes to keep after applying NMS to RPN proposals\n__C.TEST.RPN_POST_NMS_TOP_N = 1000",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.PROPOSAL_METHOD",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.PROPOSAL_METHOD = 'selective_search'\n## NMS threshold used on RPN proposals\n__C.TEST.RPN_NMS_THRESH = 0.7\n## Number of top scoring boxes to keep before apply NMS to RPN proposals\n#__C.TEST.RPN_PRE_NMS_TOP_N = 6000\n__C.TEST.RPN_PRE_NMS_TOP_N = 12000\n## Number of top scoring boxes to keep after applying NMS to RPN proposals\n__C.TEST.RPN_POST_NMS_TOP_N = 1000\n#__C.TEST.RPN_POST_NMS_TOP_N = 2000\n# Proposal height and width both need to be greater than RPN_MIN_SIZE (at orig image scale)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.RPN_NMS_THRESH",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.RPN_NMS_THRESH = 0.7\n## Number of top scoring boxes to keep before apply NMS to RPN proposals\n#__C.TEST.RPN_PRE_NMS_TOP_N = 6000\n__C.TEST.RPN_PRE_NMS_TOP_N = 12000\n## Number of top scoring boxes to keep after applying NMS to RPN proposals\n__C.TEST.RPN_POST_NMS_TOP_N = 1000\n#__C.TEST.RPN_POST_NMS_TOP_N = 2000\n# Proposal height and width both need to be greater than RPN_MIN_SIZE (at orig image scale)\n__C.TEST.RPN_MIN_SIZE = 8\n#",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "#__C.TEST.RPN_PRE_NMS_TOP_N",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "#__C.TEST.RPN_PRE_NMS_TOP_N = 6000\n__C.TEST.RPN_PRE_NMS_TOP_N = 12000\n## Number of top scoring boxes to keep after applying NMS to RPN proposals\n__C.TEST.RPN_POST_NMS_TOP_N = 1000\n#__C.TEST.RPN_POST_NMS_TOP_N = 2000\n# Proposal height and width both need to be greater than RPN_MIN_SIZE (at orig image scale)\n__C.TEST.RPN_MIN_SIZE = 8\n#\n# MISC\n#",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.RPN_PRE_NMS_TOP_N",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.RPN_PRE_NMS_TOP_N = 12000\n## Number of top scoring boxes to keep after applying NMS to RPN proposals\n__C.TEST.RPN_POST_NMS_TOP_N = 1000\n#__C.TEST.RPN_POST_NMS_TOP_N = 2000\n# Proposal height and width both need to be greater than RPN_MIN_SIZE (at orig image scale)\n__C.TEST.RPN_MIN_SIZE = 8\n#\n# MISC\n#\n# The mapping from image coordinates to feature map coordinates might cause",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.RPN_POST_NMS_TOP_N",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.RPN_POST_NMS_TOP_N = 1000\n#__C.TEST.RPN_POST_NMS_TOP_N = 2000\n# Proposal height and width both need to be greater than RPN_MIN_SIZE (at orig image scale)\n__C.TEST.RPN_MIN_SIZE = 8\n#\n# MISC\n#\n# The mapping from image coordinates to feature map coordinates might cause\n# some boxes that are distinct in image space to become identical in feature\n# coordinates. If DEDUP_BOXES > 0, then DEDUP_BOXES is used as the scale factor",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "#__C.TEST.RPN_POST_NMS_TOP_N",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "#__C.TEST.RPN_POST_NMS_TOP_N = 2000\n# Proposal height and width both need to be greater than RPN_MIN_SIZE (at orig image scale)\n__C.TEST.RPN_MIN_SIZE = 8\n#\n# MISC\n#\n# The mapping from image coordinates to feature map coordinates might cause\n# some boxes that are distinct in image space to become identical in feature\n# coordinates. If DEDUP_BOXES > 0, then DEDUP_BOXES is used as the scale factor\n# for identifying duplicate boxes.",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.TEST.RPN_MIN_SIZE",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.TEST.RPN_MIN_SIZE = 8\n#\n# MISC\n#\n# The mapping from image coordinates to feature map coordinates might cause\n# some boxes that are distinct in image space to become identical in feature\n# coordinates. If DEDUP_BOXES > 0, then DEDUP_BOXES is used as the scale factor\n# for identifying duplicate boxes.\n# 1/16 is correct for {Alex,Caffe}Net, VGG_CNN_M_1024, and VGG16\n__C.DEDUP_BOXES = 1./16.",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.DEDUP_BOXES",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.DEDUP_BOXES = 1./16.\n# Pixel mean values (BGR order) as a (1, 1, 3) array\n# We use the same pixel mean for all networks even though it's not exactly what\n# they were trained with\n__C.PIXEL_MEANS = np.array([[[102.9801, 115.9465, 122.7717]]])\n# For reproducibility\n#__C.RNG_SEED = 3\n__C.RNG_SEED = 3\n# A small number that's used many times\n__C.EPS = 1e-14",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.PIXEL_MEANS",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.PIXEL_MEANS = np.array([[[102.9801, 115.9465, 122.7717]]])\n# For reproducibility\n#__C.RNG_SEED = 3\n__C.RNG_SEED = 3\n# A small number that's used many times\n__C.EPS = 1e-14\n# Root directory of project\n__C.ROOT_DIR = osp.abspath(osp.join(osp.dirname(__file__), '..', '..'))\n# Data directory\n__C.DATA_DIR = osp.abspath(osp.join(__C.ROOT_DIR, 'data'))",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "#__C.RNG_SEED",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "#__C.RNG_SEED = 3\n__C.RNG_SEED = 3\n# A small number that's used many times\n__C.EPS = 1e-14\n# Root directory of project\n__C.ROOT_DIR = osp.abspath(osp.join(osp.dirname(__file__), '..', '..'))\n# Data directory\n__C.DATA_DIR = osp.abspath(osp.join(__C.ROOT_DIR, 'data'))\n# Model directory\n__C.MODELS_DIR = osp.abspath(osp.join(__C.ROOT_DIR, 'models', 'pascal_voc'))",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.RNG_SEED",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.RNG_SEED = 3\n# A small number that's used many times\n__C.EPS = 1e-14\n# Root directory of project\n__C.ROOT_DIR = osp.abspath(osp.join(osp.dirname(__file__), '..', '..'))\n# Data directory\n__C.DATA_DIR = osp.abspath(osp.join(__C.ROOT_DIR, 'data'))\n# Model directory\n__C.MODELS_DIR = osp.abspath(osp.join(__C.ROOT_DIR, 'models', 'pascal_voc'))\n# Name (or path to) the matlab executable",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.EPS",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.EPS = 1e-14\n# Root directory of project\n__C.ROOT_DIR = osp.abspath(osp.join(osp.dirname(__file__), '..', '..'))\n# Data directory\n__C.DATA_DIR = osp.abspath(osp.join(__C.ROOT_DIR, 'data'))\n# Model directory\n__C.MODELS_DIR = osp.abspath(osp.join(__C.ROOT_DIR, 'models', 'pascal_voc'))\n# Name (or path to) the matlab executable\n__C.MATLAB = 'matlab'\n# Place outputs under an experiments directory",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.ROOT_DIR",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.ROOT_DIR = osp.abspath(osp.join(osp.dirname(__file__), '..', '..'))\n# Data directory\n__C.DATA_DIR = osp.abspath(osp.join(__C.ROOT_DIR, 'data'))\n# Model directory\n__C.MODELS_DIR = osp.abspath(osp.join(__C.ROOT_DIR, 'models', 'pascal_voc'))\n# Name (or path to) the matlab executable\n__C.MATLAB = 'matlab'\n# Place outputs under an experiments directory\n__C.EXP_DIR = 'default'\n__C.LOG_DIR = 'default'",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.DATA_DIR",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.DATA_DIR = osp.abspath(osp.join(__C.ROOT_DIR, 'data'))\n# Model directory\n__C.MODELS_DIR = osp.abspath(osp.join(__C.ROOT_DIR, 'models', 'pascal_voc'))\n# Name (or path to) the matlab executable\n__C.MATLAB = 'matlab'\n# Place outputs under an experiments directory\n__C.EXP_DIR = 'default'\n__C.LOG_DIR = 'default'\n# Use GPU implementation of non-maximum suppression\n__C.USE_GPU_NMS = True",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.MODELS_DIR",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.MODELS_DIR = osp.abspath(osp.join(__C.ROOT_DIR, 'models', 'pascal_voc'))\n# Name (or path to) the matlab executable\n__C.MATLAB = 'matlab'\n# Place outputs under an experiments directory\n__C.EXP_DIR = 'default'\n__C.LOG_DIR = 'default'\n# Use GPU implementation of non-maximum suppression\n__C.USE_GPU_NMS = True\ndef get_output_dir(imdb, weights_filename):\n    \"\"\"Return the directory where experimental artifacts are placed.",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.MATLAB",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.MATLAB = 'matlab'\n# Place outputs under an experiments directory\n__C.EXP_DIR = 'default'\n__C.LOG_DIR = 'default'\n# Use GPU implementation of non-maximum suppression\n__C.USE_GPU_NMS = True\ndef get_output_dir(imdb, weights_filename):\n    \"\"\"Return the directory where experimental artifacts are placed.\n    If the directory does not exist, it is created.\n    A canonical path is built using the name from an imdb and a network",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.EXP_DIR",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.EXP_DIR = 'default'\n__C.LOG_DIR = 'default'\n# Use GPU implementation of non-maximum suppression\n__C.USE_GPU_NMS = True\ndef get_output_dir(imdb, weights_filename):\n    \"\"\"Return the directory where experimental artifacts are placed.\n    If the directory does not exist, it is created.\n    A canonical path is built using the name from an imdb and a network\n    (if not None).\n    \"\"\"",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.LOG_DIR",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.LOG_DIR = 'default'\n# Use GPU implementation of non-maximum suppression\n__C.USE_GPU_NMS = True\ndef get_output_dir(imdb, weights_filename):\n    \"\"\"Return the directory where experimental artifacts are placed.\n    If the directory does not exist, it is created.\n    A canonical path is built using the name from an imdb and a network\n    (if not None).\n    \"\"\"\n    outdir = osp.abspath(osp.join(__C.ROOT_DIR, 'output', __C.EXP_DIR, imdb.name))",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "__C.USE_GPU_NMS",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.config",
        "description": "nutrition_extractor.lib.fast_rcnn.config",
        "peekOfCode": "__C.USE_GPU_NMS = True\ndef get_output_dir(imdb, weights_filename):\n    \"\"\"Return the directory where experimental artifacts are placed.\n    If the directory does not exist, it is created.\n    A canonical path is built using the name from an imdb and a network\n    (if not None).\n    \"\"\"\n    outdir = osp.abspath(osp.join(__C.ROOT_DIR, 'output', __C.EXP_DIR, imdb.name))\n    if weights_filename is not None:\n        outdir = osp.join(outdir, weights_filename)",
        "detail": "nutrition_extractor.lib.fast_rcnn.config",
        "documentation": {}
    },
    {
        "label": "nms",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.nms_wrapper",
        "description": "nutrition_extractor.lib.fast_rcnn.nms_wrapper",
        "peekOfCode": "def nms(dets, thresh):\n    if dets.shape[0] == 0:\n        return []\n    if pure_python_nms:\n        # print(\"Fall back to pure python nms\")\n        return py_cpu_nms(dets, thresh)\n    if cfg.USE_GPU_NMS:\n        return gpu_nms(dets, thresh, device_id=cfg.GPU_ID)\n    else:\n        return cython_nms(dets, thresh)",
        "detail": "nutrition_extractor.lib.fast_rcnn.nms_wrapper",
        "documentation": {}
    },
    {
        "label": "py_cpu_nms",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.nms_wrapper",
        "description": "nutrition_extractor.lib.fast_rcnn.nms_wrapper",
        "peekOfCode": "def py_cpu_nms(dets, thresh):\n    x1 = dets[:, 0]\n    y1 = dets[:, 1]\n    x2 = dets[:, 2]\n    y2 = dets[:, 3]\n    scores = dets[:, 4]\n    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n    order = scores.argsort()[::-1]\n    keep = []\n    while order.size > 0:",
        "detail": "nutrition_extractor.lib.fast_rcnn.nms_wrapper",
        "documentation": {}
    },
    {
        "label": "pure_python_nms",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.nms_wrapper",
        "description": "nutrition_extractor.lib.fast_rcnn.nms_wrapper",
        "peekOfCode": "pure_python_nms = False\ntry:\n    from lib.utils.gpu_nms import gpu_nms\n    from ..utils.cython_nms import nms as cython_nms\nexcept ImportError:\n    pure_python_nms = True\ndef nms(dets, thresh):\n    if dets.shape[0] == 0:\n        return []\n    if pure_python_nms:",
        "detail": "nutrition_extractor.lib.fast_rcnn.nms_wrapper",
        "documentation": {}
    },
    {
        "label": "test_ctpn",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.test",
        "description": "nutrition_extractor.lib.fast_rcnn.test",
        "peekOfCode": "def test_ctpn(sess, net, im, boxes=None):\n    blobs, im_scales = _get_blobs(im, boxes)\n    if cfg.TEST.HAS_RPN:\n        im_blob = blobs['data']\n        blobs['im_info'] = np.array(\n            [[im_blob.shape[1], im_blob.shape[2], im_scales[0]]],\n            dtype=np.float32)\n    # forward pass\n    if cfg.TEST.HAS_RPN:\n        feed_dict = {net.data: blobs['data'], net.im_info: blobs['im_info'], net.keep_prob: 1.0}",
        "detail": "nutrition_extractor.lib.fast_rcnn.test",
        "documentation": {}
    },
    {
        "label": "SolverWrapper",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.fast_rcnn.train",
        "description": "nutrition_extractor.lib.fast_rcnn.train",
        "peekOfCode": "class SolverWrapper(object):\n    def __init__(self, sess, network, imdb, roidb, output_dir, logdir, pretrained_model=None):\n        \"\"\"Initialize the SolverWrapper.\"\"\"\n        self.net = network\n        self.imdb = imdb\n        self.roidb = roidb\n        self.output_dir = output_dir\n        self.pretrained_model = pretrained_model\n        print('Computing bounding-box regression targets...')\n        if cfg.TRAIN.BBOX_REG:",
        "detail": "nutrition_extractor.lib.fast_rcnn.train",
        "documentation": {}
    },
    {
        "label": "get_training_roidb",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.train",
        "description": "nutrition_extractor.lib.fast_rcnn.train",
        "peekOfCode": "def get_training_roidb(imdb):\n    \"\"\"Returns a roidb (Region of Interest database) for use in training.\"\"\"\n    if cfg.TRAIN.USE_FLIPPED:\n        print('Appending horizontally-flipped training examples...')\n        imdb.append_flipped_images()\n        print('done')\n    print('Preparing training data...')\n    if cfg.TRAIN.HAS_RPN:\n            rdl_roidb.prepare_roidb(imdb)\n    else:",
        "detail": "nutrition_extractor.lib.fast_rcnn.train",
        "documentation": {}
    },
    {
        "label": "get_data_layer",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.train",
        "description": "nutrition_extractor.lib.fast_rcnn.train",
        "peekOfCode": "def get_data_layer(roidb, num_classes):\n    \"\"\"return a data layer.\"\"\"\n    if cfg.TRAIN.HAS_RPN:\n        if cfg.IS_MULTISCALE:\n            # obsolete\n            # layer = GtDataLayer(roidb)\n            raise \"Calling caffe modules...\"\n        else:\n            layer = RoIDataLayer(roidb, num_classes)\n    else:",
        "detail": "nutrition_extractor.lib.fast_rcnn.train",
        "documentation": {}
    },
    {
        "label": "train_net",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.fast_rcnn.train",
        "description": "nutrition_extractor.lib.fast_rcnn.train",
        "peekOfCode": "def train_net(network, imdb, roidb, output_dir, log_dir, pretrained_model=None, max_iters=40000, restore=False):\n    \"\"\"Train a Fast R-CNN network.\"\"\"\n    config = tf.ConfigProto(allow_soft_placement=True)\n    config.gpu_options.allocator_type = 'BFC'\n    config.gpu_options.per_process_gpu_memory_fraction = 0.75\n    with tf.Session(config=config) as sess:\n        sw = SolverWrapper(sess, network, imdb, roidb, output_dir, logdir= log_dir, pretrained_model=pretrained_model)\n        print('Solving...')\n        sw.train_model(sess, max_iters, restore=restore)\n        print('done solving')",
        "detail": "nutrition_extractor.lib.fast_rcnn.train",
        "documentation": {}
    },
    {
        "label": "_DEBUG",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.fast_rcnn.train",
        "description": "nutrition_extractor.lib.fast_rcnn.train",
        "peekOfCode": "_DEBUG = False\nclass SolverWrapper(object):\n    def __init__(self, sess, network, imdb, roidb, output_dir, logdir, pretrained_model=None):\n        \"\"\"Initialize the SolverWrapper.\"\"\"\n        self.net = network\n        self.imdb = imdb\n        self.roidb = roidb\n        self.output_dir = output_dir\n        self.pretrained_model = pretrained_model\n        print('Computing bounding-box regression targets...')",
        "detail": "nutrition_extractor.lib.fast_rcnn.train",
        "documentation": {}
    },
    {
        "label": "VGGnet_test",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.networks.VGGnet_test",
        "description": "nutrition_extractor.lib.networks.VGGnet_test",
        "peekOfCode": "class VGGnet_test(Network):\n    def __init__(self, trainable=True):\n        self.inputs = []\n        self.data = tf.placeholder(tf.float32, shape=[None, None, None, 3])\n        self.im_info = tf.placeholder(tf.float32, shape=[None, 3])\n        self.keep_prob = tf.placeholder(tf.float32)\n        self.layers = dict({'data': self.data, 'im_info': self.im_info})\n        self.trainable = trainable\n        self.setup()\n    def setup(self):",
        "detail": "nutrition_extractor.lib.networks.VGGnet_test",
        "documentation": {}
    },
    {
        "label": "VGGnet_train",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.networks.VGGnet_train",
        "description": "nutrition_extractor.lib.networks.VGGnet_train",
        "peekOfCode": "class VGGnet_train(Network):\n    def __init__(self, trainable=True):\n        self.inputs = []\n        self.data = tf.placeholder(tf.float32, shape=[None, None, None, 3], name='data')\n        self.im_info = tf.placeholder(tf.float32, shape=[None, 3], name='im_info')\n        self.gt_boxes = tf.placeholder(tf.float32, shape=[None, 5], name='gt_boxes')\n        self.gt_ishard = tf.placeholder(tf.int32, shape=[None], name='gt_ishard')\n        self.dontcare_areas = tf.placeholder(tf.float32, shape=[None, 4], name='dontcare_areas')\n        self.keep_prob = tf.placeholder(tf.float32)\n        self.layers = dict({'data':self.data, 'im_info':self.im_info, 'gt_boxes':self.gt_boxes,\\",
        "detail": "nutrition_extractor.lib.networks.VGGnet_train",
        "documentation": {}
    },
    {
        "label": "get_network",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.networks.factory",
        "description": "nutrition_extractor.lib.networks.factory",
        "peekOfCode": "def get_network(name):\n    \"\"\"Get a network by name.\"\"\"\n    if name.split('_')[0] == 'VGGnet':\n        if name.split('_')[1] == 'test':\n           return VGGnet_test()\n        elif name.split('_')[1] == 'train':\n           return VGGnet_train()\n        else:\n           raise KeyError('Unknown dataset: {}'.format(name))\n    else:",
        "detail": "nutrition_extractor.lib.networks.factory",
        "documentation": {}
    },
    {
        "label": "Network",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.networks.network",
        "description": "nutrition_extractor.lib.networks.network",
        "peekOfCode": "class Network(object):\n    def __init__(self, inputs, trainable=True):\n        self.inputs = []\n        self.layers = dict(inputs)\n        self.trainable = trainable\n        self.setup()\n    def setup(self):\n        raise NotImplementedError('Must be subclassed.')\n    def load(self, data_path, session, ignore_missing=False):\n        data_dict = np.load(data_path,encoding='latin1').item()",
        "detail": "nutrition_extractor.lib.networks.network",
        "documentation": {}
    },
    {
        "label": "layer",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.networks.network",
        "description": "nutrition_extractor.lib.networks.network",
        "peekOfCode": "def layer(op):\n    def layer_decorated(self, *args, **kwargs):\n        # Automatically set a name if not provided.\n        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n        # Figure out the layer inputs.\n        if len(self.inputs)==0:\n            raise RuntimeError('No input variables found for layer %s.'%name)\n        elif len(self.inputs)==1:\n            layer_input = self.inputs[0]\n        else:",
        "detail": "nutrition_extractor.lib.networks.network",
        "documentation": {}
    },
    {
        "label": "DEFAULT_PADDING",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.networks.network",
        "description": "nutrition_extractor.lib.networks.network",
        "peekOfCode": "DEFAULT_PADDING = 'SAME'\ndef layer(op):\n    def layer_decorated(self, *args, **kwargs):\n        # Automatically set a name if not provided.\n        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n        # Figure out the layer inputs.\n        if len(self.inputs)==0:\n            raise RuntimeError('No input variables found for layer %s.'%name)\n        elif len(self.inputs)==1:\n            layer_input = self.inputs[0]",
        "detail": "nutrition_extractor.lib.networks.network",
        "documentation": {}
    },
    {
        "label": "generate_xml",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.prepare_training_data.ToVoc",
        "description": "nutrition_extractor.lib.prepare_training_data.ToVoc",
        "peekOfCode": "def generate_xml(name, lines, img_size, class_sets, doncateothers=True):\n    doc = Document()\n    def append_xml_node_attr(child, parent=None, text=None):\n        ele = doc.createElement(child)\n        if not text is None:\n            text_node = doc.createTextNode(text)\n            ele.appendChild(text_node)\n        parent = doc if parent is None else parent\n        parent.appendChild(ele)\n        return ele",
        "detail": "nutrition_extractor.lib.prepare_training_data.ToVoc",
        "documentation": {}
    },
    {
        "label": "build_voc_dirs",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.prepare_training_data.ToVoc",
        "description": "nutrition_extractor.lib.prepare_training_data.ToVoc",
        "peekOfCode": "def build_voc_dirs(outdir):\n    mkdir = lambda dir: os.makedirs(dir) if not os.path.exists(dir) else None\n    mkdir(outdir)\n    mkdir(os.path.join(outdir, 'Annotations'))\n    mkdir(os.path.join(outdir, 'ImageSets'))\n    mkdir(os.path.join(outdir, 'ImageSets', 'Layout'))\n    mkdir(os.path.join(outdir, 'ImageSets', 'Main'))\n    mkdir(os.path.join(outdir, 'ImageSets', 'Segmentation'))\n    mkdir(os.path.join(outdir, 'JPEGImages'))\n    mkdir(os.path.join(outdir, 'SegmentationClass'))",
        "detail": "nutrition_extractor.lib.prepare_training_data.ToVoc",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.prepare_training_data.split_label",
        "description": "nutrition_extractor.lib.prepare_training_data.split_label",
        "peekOfCode": "path = '/media/D/code/OCR/text-detection-ctpn/data/mlt_english+chinese/image'\ngt_path = '/media/D/code/OCR/text-detection-ctpn/data/mlt_english+chinese/label'\nout_path = 're_image'\nif not os.path.exists(out_path):\n    os.makedirs(out_path)\nfiles = os.listdir(path)\nfiles.sort()\n#files=files[:100]\nfor file in files:\n    _, basename = os.path.split(file)",
        "detail": "nutrition_extractor.lib.prepare_training_data.split_label",
        "documentation": {}
    },
    {
        "label": "gt_path",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.prepare_training_data.split_label",
        "description": "nutrition_extractor.lib.prepare_training_data.split_label",
        "peekOfCode": "gt_path = '/media/D/code/OCR/text-detection-ctpn/data/mlt_english+chinese/label'\nout_path = 're_image'\nif not os.path.exists(out_path):\n    os.makedirs(out_path)\nfiles = os.listdir(path)\nfiles.sort()\n#files=files[:100]\nfor file in files:\n    _, basename = os.path.split(file)\n    if basename.lower().split('.')[-1] not in ['jpg', 'png']:",
        "detail": "nutrition_extractor.lib.prepare_training_data.split_label",
        "documentation": {}
    },
    {
        "label": "out_path",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.prepare_training_data.split_label",
        "description": "nutrition_extractor.lib.prepare_training_data.split_label",
        "peekOfCode": "out_path = 're_image'\nif not os.path.exists(out_path):\n    os.makedirs(out_path)\nfiles = os.listdir(path)\nfiles.sort()\n#files=files[:100]\nfor file in files:\n    _, basename = os.path.split(file)\n    if basename.lower().split('.')[-1] not in ['jpg', 'png']:\n        continue",
        "detail": "nutrition_extractor.lib.prepare_training_data.split_label",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.prepare_training_data.split_label",
        "description": "nutrition_extractor.lib.prepare_training_data.split_label",
        "peekOfCode": "files = os.listdir(path)\nfiles.sort()\n#files=files[:100]\nfor file in files:\n    _, basename = os.path.split(file)\n    if basename.lower().split('.')[-1] not in ['jpg', 'png']:\n        continue\n    stem, ext = os.path.splitext(basename)\n    gt_file = os.path.join(gt_path, 'gt_' + stem + '.txt')\n    img_path = os.path.join(path, file)",
        "detail": "nutrition_extractor.lib.prepare_training_data.split_label",
        "documentation": {}
    },
    {
        "label": "RoIDataLayer",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.roi_data_layer.layer",
        "description": "nutrition_extractor.lib.roi_data_layer.layer",
        "peekOfCode": "class RoIDataLayer(object):\n    \"\"\"Fast R-CNN data layer used for training.\"\"\"\n    def __init__(self, roidb, num_classes):\n        \"\"\"Set the roidb to be used by this layer during training.\"\"\"\n        self._roidb = roidb\n        self._num_classes = num_classes\n        self._shuffle_roidb_inds()\n    def _shuffle_roidb_inds(self):\n        \"\"\"Randomly permute the training roidb.\"\"\"\n        self._perm = np.random.permutation(np.arange(len(self._roidb)))",
        "detail": "nutrition_extractor.lib.roi_data_layer.layer",
        "documentation": {}
    },
    {
        "label": "get_minibatch",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.roi_data_layer.minibatch",
        "description": "nutrition_extractor.lib.roi_data_layer.minibatch",
        "peekOfCode": "def get_minibatch(roidb, num_classes):\n    \"\"\"Given a roidb, construct a minibatch sampled from it.\"\"\"\n    num_images = len(roidb)\n    # Sample random scales to use for each image in this batch\n    random_scale_inds = npr.randint(0, high=len(cfg.TRAIN.SCALES),\n                                    size=num_images)\n    assert(cfg.TRAIN.BATCH_SIZE % num_images == 0), \\\n        'num_images ({}) must divide BATCH_SIZE ({})'. \\\n        format(num_images, cfg.TRAIN.BATCH_SIZE)\n    rois_per_image = cfg.TRAIN.BATCH_SIZE / num_images",
        "detail": "nutrition_extractor.lib.roi_data_layer.minibatch",
        "documentation": {}
    },
    {
        "label": "prepare_roidb",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.roi_data_layer.roidb",
        "description": "nutrition_extractor.lib.roi_data_layer.roidb",
        "peekOfCode": "def prepare_roidb(imdb):\n    \"\"\"Enrich the imdb's roidb by adding some derived quantities that\n    are useful for training. This function precomputes the maximum\n    overlap, taken over ground-truth boxes, between each ROI and\n    each ground-truth box. The class with maximum overlap is also\n    recorded.\n    \"\"\"\n    sizes = [PIL.Image.open(imdb.image_path_at(i)).size\n             for i in range(imdb.num_images)]\n    roidb = imdb.roidb",
        "detail": "nutrition_extractor.lib.roi_data_layer.roidb",
        "documentation": {}
    },
    {
        "label": "add_bbox_regression_targets",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.roi_data_layer.roidb",
        "description": "nutrition_extractor.lib.roi_data_layer.roidb",
        "peekOfCode": "def add_bbox_regression_targets(roidb):\n    \"\"\"\n    Add information needed to train bounding-box regressors.\n    For each roi find the corresponding gt box, and compute the distance.\n    then normalize the distance into Gaussian by minus mean and divided by std\n    \"\"\"\n    assert len(roidb) > 0\n    assert 'max_classes' in roidb[0], 'Did you call prepare_roidb first?'\n    num_images = len(roidb)\n    # Infer number of classes from the number of columns in gt_overlaps",
        "detail": "nutrition_extractor.lib.roi_data_layer.roidb",
        "documentation": {}
    },
    {
        "label": "anchor_target_layer",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.rpn_msr.anchor_target_layer_tf",
        "description": "nutrition_extractor.lib.rpn_msr.anchor_target_layer_tf",
        "peekOfCode": "def anchor_target_layer(rpn_cls_score, gt_boxes, gt_ishard, dontcare_areas, im_info, _feat_stride = [16,], anchor_scales = [16,]):\n    \"\"\"\n    Assign anchors to ground-truth targets. Produces anchor classification\n    labels and bounding-box regression targets.\n    Parameters\n    ----------\n    rpn_cls_score: (1, H, W, Ax2) bg/fg scores of previous conv layer\n    gt_boxes: (G, 5) vstack of [x1, y1, x2, y2, class]\n    gt_ishard: (G, 1), 1 or 0 indicates difficult or not\n    dontcare_areas: (D, 4), some areas may contains small objs but no labelling. D may be 0",
        "detail": "nutrition_extractor.lib.rpn_msr.anchor_target_layer_tf",
        "documentation": {}
    },
    {
        "label": "DEBUG",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.rpn_msr.anchor_target_layer_tf",
        "description": "nutrition_extractor.lib.rpn_msr.anchor_target_layer_tf",
        "peekOfCode": "DEBUG = False\ndef anchor_target_layer(rpn_cls_score, gt_boxes, gt_ishard, dontcare_areas, im_info, _feat_stride = [16,], anchor_scales = [16,]):\n    \"\"\"\n    Assign anchors to ground-truth targets. Produces anchor classification\n    labels and bounding-box regression targets.\n    Parameters\n    ----------\n    rpn_cls_score: (1, H, W, Ax2) bg/fg scores of previous conv layer\n    gt_boxes: (G, 5) vstack of [x1, y1, x2, y2, class]\n    gt_ishard: (G, 1), 1 or 0 indicates difficult or not",
        "detail": "nutrition_extractor.lib.rpn_msr.anchor_target_layer_tf",
        "documentation": {}
    },
    {
        "label": "generate_basic_anchors",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.rpn_msr.generate_anchors",
        "description": "nutrition_extractor.lib.rpn_msr.generate_anchors",
        "peekOfCode": "def generate_basic_anchors(sizes, base_size=16):\n    base_anchor = np.array([0, 0, base_size - 1, base_size - 1], np.int32)\n    anchors = np.zeros((len(sizes), 4), np.int32)\n    index = 0\n    for h, w in sizes:\n        anchors[index] = scale_anchor(base_anchor, h, w)\n        index += 1\n    return anchors\ndef scale_anchor(anchor, h, w):\n    x_ctr = (anchor[0] + anchor[2]) * 0.5",
        "detail": "nutrition_extractor.lib.rpn_msr.generate_anchors",
        "documentation": {}
    },
    {
        "label": "scale_anchor",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.rpn_msr.generate_anchors",
        "description": "nutrition_extractor.lib.rpn_msr.generate_anchors",
        "peekOfCode": "def scale_anchor(anchor, h, w):\n    x_ctr = (anchor[0] + anchor[2]) * 0.5\n    y_ctr = (anchor[1] + anchor[3]) * 0.5\n    scaled_anchor = anchor.copy()\n    scaled_anchor[0] = x_ctr - w / 2  # xmin\n    scaled_anchor[2] = x_ctr + w / 2  # xmax\n    scaled_anchor[1] = y_ctr - h / 2  # ymin\n    scaled_anchor[3] = y_ctr + h / 2  # ymax\n    return scaled_anchor\ndef generate_anchors(base_size=16, ratios=[0.5, 1, 2],",
        "detail": "nutrition_extractor.lib.rpn_msr.generate_anchors",
        "documentation": {}
    },
    {
        "label": "generate_anchors",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.rpn_msr.generate_anchors",
        "description": "nutrition_extractor.lib.rpn_msr.generate_anchors",
        "peekOfCode": "def generate_anchors(base_size=16, ratios=[0.5, 1, 2],\n                     scales=2**np.arange(3, 6)):\n    heights = [11, 16, 23, 33, 48, 68, 97, 139, 198, 283]\n    widths = [16]\n    sizes = []\n    for h in heights:\n        for w in widths:\n            sizes.append((h, w))\n    return generate_basic_anchors(sizes)\nif __name__ == '__main__':",
        "detail": "nutrition_extractor.lib.rpn_msr.generate_anchors",
        "documentation": {}
    },
    {
        "label": "proposal_layer",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.rpn_msr.proposal_layer_tf",
        "description": "nutrition_extractor.lib.rpn_msr.proposal_layer_tf",
        "peekOfCode": "def proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg_key, _feat_stride = [16,], anchor_scales = [16,]):\n    \"\"\"\n    Parameters\n    ----------\n    rpn_cls_prob_reshape: (1 , H , W , Ax2) outputs of RPN, prob of bg or fg\n                         NOTICE: the old version is ordered by (1, H, W, 2, A) !!!!\n    rpn_bbox_pred: (1 , H , W , Ax4), rgs boxes output of RPN\n    im_info: a list of [image_height, image_width, scale_ratios]\n    cfg_key: 'TRAIN' or 'TEST'\n    _feat_stride: the downsampling ratio of feature map to the original input image",
        "detail": "nutrition_extractor.lib.rpn_msr.proposal_layer_tf",
        "documentation": {}
    },
    {
        "label": "DEBUG",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.rpn_msr.proposal_layer_tf",
        "description": "nutrition_extractor.lib.rpn_msr.proposal_layer_tf",
        "peekOfCode": "DEBUG = False\n\"\"\"\nOutputs object detection proposals by applying estimated bounding-box\ntransformations to a set of regular boxes (called \"anchors\").\n\"\"\"\ndef proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg_key, _feat_stride = [16,], anchor_scales = [16,]):\n    \"\"\"\n    Parameters\n    ----------\n    rpn_cls_prob_reshape: (1 , H , W , Ax2) outputs of RPN, prob of bg or fg",
        "detail": "nutrition_extractor.lib.rpn_msr.proposal_layer_tf",
        "documentation": {}
    },
    {
        "label": "TextDetector",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.text_connector.detectors",
        "description": "nutrition_extractor.lib.text_connector.detectors",
        "peekOfCode": "class TextDetector:\n    def __init__(self):\n        self.mode= cfg.TEST.DETECT_MODE\n        if self.mode == \"H\":\n            self.text_proposal_connector=TextProposalConnector()\n        elif self.mode == \"O\":\n            self.text_proposal_connector=TextProposalConnectorOriented()\n    def detect(self, text_proposals,scores,size):\n        # 删除得分较低的proposal\n        keep_inds=np.where(scores>TextLineCfg.TEXT_PROPOSALS_MIN_SCORE)[0]",
        "detail": "nutrition_extractor.lib.text_connector.detectors",
        "documentation": {}
    },
    {
        "label": "Graph",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.text_connector.other",
        "description": "nutrition_extractor.lib.text_connector.other",
        "peekOfCode": "class Graph:\n    def __init__(self, graph):\n        self.graph=graph\n    def sub_graphs_connected(self):\n        sub_graphs=[]\n        for index in range(self.graph.shape[0]):\n            if not self.graph[:, index].any() and self.graph[index, :].any():\n                v=index\n                sub_graphs.append([v])\n                while self.graph[v, :].any():",
        "detail": "nutrition_extractor.lib.text_connector.other",
        "documentation": {}
    },
    {
        "label": "threshold",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.text_connector.other",
        "description": "nutrition_extractor.lib.text_connector.other",
        "peekOfCode": "def threshold(coords, min_, max_):\n    return np.maximum(np.minimum(coords, max_), min_)\ndef clip_boxes(boxes, im_shape):\n    \"\"\"\n    Clip boxes to image boundaries.\n    \"\"\"\n    boxes[:, 0::2]=threshold(boxes[:, 0::2], 0, im_shape[1]-1)\n    boxes[:, 1::2]=threshold(boxes[:, 1::2], 0, im_shape[0]-1)\n    return boxes\nclass Graph:",
        "detail": "nutrition_extractor.lib.text_connector.other",
        "documentation": {}
    },
    {
        "label": "clip_boxes",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.text_connector.other",
        "description": "nutrition_extractor.lib.text_connector.other",
        "peekOfCode": "def clip_boxes(boxes, im_shape):\n    \"\"\"\n    Clip boxes to image boundaries.\n    \"\"\"\n    boxes[:, 0::2]=threshold(boxes[:, 0::2], 0, im_shape[1]-1)\n    boxes[:, 1::2]=threshold(boxes[:, 1::2], 0, im_shape[0]-1)\n    return boxes\nclass Graph:\n    def __init__(self, graph):\n        self.graph=graph",
        "detail": "nutrition_extractor.lib.text_connector.other",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.text_connector.text_connect_cfg",
        "description": "nutrition_extractor.lib.text_connector.text_connect_cfg",
        "peekOfCode": "class Config:\n    SCALE=600\n    MAX_SCALE=1200\n    TEXT_PROPOSALS_WIDTH=16\n    MIN_NUM_PROPOSALS = 2\n    MIN_RATIO=0.5\n    LINE_MIN_SCORE=0.9\n    MAX_HORIZONTAL_GAP=50\n    TEXT_PROPOSALS_MIN_SCORE=0.7\n    TEXT_PROPOSALS_NMS_THRESH=0.2",
        "detail": "nutrition_extractor.lib.text_connector.text_connect_cfg",
        "documentation": {}
    },
    {
        "label": "TextProposalConnector",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.text_connector.text_proposal_connector",
        "description": "nutrition_extractor.lib.text_connector.text_proposal_connector",
        "peekOfCode": "class TextProposalConnector:\n    def __init__(self):\n        self.graph_builder=TextProposalGraphBuilder()\n    def group_text_proposals(self, text_proposals, scores, im_size):\n        graph=self.graph_builder.build_graph(text_proposals, scores, im_size)\n        return graph.sub_graphs_connected()\n    def fit_y(self, X, Y, x1, x2):\n        len(X)!=0\n        # if X only include one point, the function will get line y=Y[0]\n        if np.sum(X==X[0])==len(X):",
        "detail": "nutrition_extractor.lib.text_connector.text_proposal_connector",
        "documentation": {}
    },
    {
        "label": "TextProposalConnector",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.text_connector.text_proposal_connector_oriented",
        "description": "nutrition_extractor.lib.text_connector.text_proposal_connector_oriented",
        "peekOfCode": "class TextProposalConnector:\n    \"\"\"\n        Connect text proposals into text lines\n    \"\"\"\n    def __init__(self):\n        self.graph_builder=TextProposalGraphBuilder()\n    def group_text_proposals(self, text_proposals, scores, im_size):\n        graph=self.graph_builder.build_graph(text_proposals, scores, im_size)\n        return graph.sub_graphs_connected()\n    def fit_y(self, X, Y, x1, x2):",
        "detail": "nutrition_extractor.lib.text_connector.text_proposal_connector_oriented",
        "documentation": {}
    },
    {
        "label": "TextProposalGraphBuilder",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.text_connector.text_proposal_graph_builder",
        "description": "nutrition_extractor.lib.text_connector.text_proposal_graph_builder",
        "peekOfCode": "class TextProposalGraphBuilder:\n    \"\"\"\n        Build Text proposals into a graph.\n    \"\"\"\n    def get_successions(self, index):\n            box=self.text_proposals[index]\n            results=[]\n            for left in range(int(box[0])+1, min(int(box[0])+TextLineCfg.MAX_HORIZONTAL_GAP+1, self.im_size[1])):\n                adj_box_indices=self.boxes_table[left]\n                for adj_box_index in adj_box_indices:",
        "detail": "nutrition_extractor.lib.text_connector.text_proposal_graph_builder",
        "documentation": {}
    },
    {
        "label": "im_list_to_blob",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.utils.blob",
        "description": "nutrition_extractor.lib.utils.blob",
        "peekOfCode": "def im_list_to_blob(ims):\n    \"\"\"Convert a list of images into a network input.\n    Assumes images are already prepared (means subtracted, BGR order, ...).\n    \"\"\"\n    max_shape = np.array([im.shape for im in ims]).max(axis=0)\n    num_images = len(ims)\n    blob = np.zeros((num_images, max_shape[0], max_shape[1], 3),\n                    dtype=np.float32)\n    for i in range(num_images):\n        im = ims[i]",
        "detail": "nutrition_extractor.lib.utils.blob",
        "documentation": {}
    },
    {
        "label": "prep_im_for_blob",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.utils.blob",
        "description": "nutrition_extractor.lib.utils.blob",
        "peekOfCode": "def prep_im_for_blob(im, pixel_means, target_size, max_size):\n    \"\"\"Mean subtract and scale an image for use in a blob.\"\"\"\n    im = im.astype(np.float32, copy=False)\n    im -= pixel_means\n    im_shape = im.shape\n    im_size_min = np.min(im_shape[0:2])\n    im_size_max = np.max(im_shape[0:2])\n    im_scale = float(target_size) / float(im_size_min)\n    # Prevent the biggest axis from being more than MAX_SIZE\n    if np.round(im_scale * im_size_max) > max_size:",
        "detail": "nutrition_extractor.lib.utils.blob",
        "documentation": {}
    },
    {
        "label": "get_boxes_grid",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.utils.boxes_grid",
        "description": "nutrition_extractor.lib.utils.boxes_grid",
        "peekOfCode": "def get_boxes_grid(image_height, image_width):\n    \"\"\"\n    Return the boxes on image grid.\n    calling this function when cfg.IS_MULTISCALE is True, otherwise, calling rdl_roidb.prepare_roidb(imdb) instead.\n    \"\"\"\n    # fixed a bug, change cfg.TRAIN.SCALES to cfg.TRAIN.SCALES_BASE\n    # coz, here needs a ratio around 1.0, not the accutual size.\n    # height and width of the feature map\n    if cfg.NET_NAME == 'CaffeNet':\n        height = np.floor((image_height * max(cfg.TRAIN.SCALES_BASE) - 1) / 4.0 + 1)",
        "detail": "nutrition_extractor.lib.utils.boxes_grid",
        "documentation": {}
    },
    {
        "label": "custom_build_ext",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.utils.setup",
        "description": "nutrition_extractor.lib.utils.setup",
        "peekOfCode": "class custom_build_ext(build_ext):\n    def build_extensions(self):\n        customize_compiler_for_nvcc(self.compiler)\n        build_ext.build_extensions(self)\next_modules = [\n    Extension(\n        \"bbox\",\n        [\"bbox.pyx\"],\n        extra_compile_args={'gcc': [\"-Wno-cpp\", \"-Wno-unused-function\"]},\n        include_dirs = [numpy_include]",
        "detail": "nutrition_extractor.lib.utils.setup",
        "documentation": {}
    },
    {
        "label": "find_in_path",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.utils.setup",
        "description": "nutrition_extractor.lib.utils.setup",
        "peekOfCode": "def find_in_path(name, path):\n    for dir in path.split(os.pathsep):\n        binpath = pjoin(dir, name)\n        if os.path.exists(binpath):\n            return os.path.abspath(binpath)\n    return None\ndef locate_cuda():\n    # first check if the CUDAHOME env variable is in use\n    if 'CUDAHOME' in os.environ:\n        home = os.environ['CUDAHOME']",
        "detail": "nutrition_extractor.lib.utils.setup",
        "documentation": {}
    },
    {
        "label": "locate_cuda",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.utils.setup",
        "description": "nutrition_extractor.lib.utils.setup",
        "peekOfCode": "def locate_cuda():\n    # first check if the CUDAHOME env variable is in use\n    if 'CUDAHOME' in os.environ:\n        home = os.environ['CUDAHOME']\n        nvcc = pjoin(home, 'bin', 'nvcc')\n    else:\n        # otherwise, search the PATH for NVCC\n        default_path = pjoin(os.sep, 'usr', 'local', 'cuda', 'bin')\n        nvcc = find_in_path('nvcc', os.environ['PATH'] + os.pathsep + default_path)\n        if nvcc is None:",
        "detail": "nutrition_extractor.lib.utils.setup",
        "documentation": {}
    },
    {
        "label": "customize_compiler_for_nvcc",
        "kind": 2,
        "importPath": "nutrition_extractor.lib.utils.setup",
        "description": "nutrition_extractor.lib.utils.setup",
        "peekOfCode": "def customize_compiler_for_nvcc(self):\n    self.src_extensions.append('.cu')\n    default_compiler_so = self.compiler_so\n    super = self._compile\n    def _compile(obj, src, ext, cc_args, extra_postargs, pp_opts):\n        print(extra_postargs)\n        if os.path.splitext(src)[1] == '.cu':\n            # use the cuda for .cu files\n            self.set_executable('compiler_so', CUDA['nvcc'])\n            # use only a subset of the extra_postargs, which are 1-1 translated",
        "detail": "nutrition_extractor.lib.utils.setup",
        "documentation": {}
    },
    {
        "label": "CUDA",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.utils.setup",
        "description": "nutrition_extractor.lib.utils.setup",
        "peekOfCode": "CUDA = locate_cuda()\ntry:\n    numpy_include = np.get_include()\nexcept AttributeError:\n    numpy_include = np.get_numpy_include()\ndef customize_compiler_for_nvcc(self):\n    self.src_extensions.append('.cu')\n    default_compiler_so = self.compiler_so\n    super = self._compile\n    def _compile(obj, src, ext, cc_args, extra_postargs, pp_opts):",
        "detail": "nutrition_extractor.lib.utils.setup",
        "documentation": {}
    },
    {
        "label": "ext_modules",
        "kind": 5,
        "importPath": "nutrition_extractor.lib.utils.setup",
        "description": "nutrition_extractor.lib.utils.setup",
        "peekOfCode": "ext_modules = [\n    Extension(\n        \"bbox\",\n        [\"bbox.pyx\"],\n        extra_compile_args={'gcc': [\"-Wno-cpp\", \"-Wno-unused-function\"]},\n        include_dirs = [numpy_include]\n    ),\n    Extension(\n        \"cython_nms\",\n        [\"cython_nms.pyx\"],",
        "detail": "nutrition_extractor.lib.utils.setup",
        "documentation": {}
    },
    {
        "label": "Timer",
        "kind": 6,
        "importPath": "nutrition_extractor.lib.utils.timer",
        "description": "nutrition_extractor.lib.utils.timer",
        "peekOfCode": "class Timer(object):\n    def __init__(self):\n        self.total_time = 0.\n        self.calls = 0\n        self.start_time = 0.\n        self.diff = 0.\n        self.average_time = 0.\n    def tic(self):\n        self.start_time = time.time()\n    def toc(self, average=True):",
        "detail": "nutrition_extractor.lib.utils.timer",
        "documentation": {}
    },
    {
        "label": "create_category_index",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.label_map_util",
        "description": "nutrition_extractor.utils.label_map_util",
        "peekOfCode": "def create_category_index(categories):\n  \"\"\"Creates dictionary of COCO compatible categories keyed by category id.\n  Args:\n    categories: a list of dicts, each of which has the following keys:\n      'id': (required) an integer id uniquely identifying this category.\n      'name': (required) string representing category name\n        e.g., 'cat', 'dog', 'pizza'.\n  Returns:\n    category_index: a dict containing the same entries as categories, but keyed\n      by the 'id' field of each category.",
        "detail": "nutrition_extractor.utils.label_map_util",
        "documentation": {}
    },
    {
        "label": "get_max_label_map_index",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.label_map_util",
        "description": "nutrition_extractor.utils.label_map_util",
        "peekOfCode": "def get_max_label_map_index(label_map):\n  \"\"\"Get maximum index in label map.\n  Args:\n    label_map: a StringIntLabelMapProto\n  Returns:\n    an integer\n  \"\"\"\n  return max([item.id for item in label_map.item])\ndef convert_label_map_to_categories(label_map,\n                                    max_num_classes,",
        "detail": "nutrition_extractor.utils.label_map_util",
        "documentation": {}
    },
    {
        "label": "convert_label_map_to_categories",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.label_map_util",
        "description": "nutrition_extractor.utils.label_map_util",
        "peekOfCode": "def convert_label_map_to_categories(label_map,\n                                    max_num_classes,\n                                    use_display_name=True):\n  \"\"\"Loads label map proto and returns categories list compatible with eval.\n  This function loads a label map and returns a list of dicts, each of which\n  has the following keys:\n    'id': (required) an integer id uniquely identifying this category.\n    'name': (required) string representing category name\n      e.g., 'cat', 'dog', 'pizza'.\n  We only allow class into the list if its id-label_id_offset is",
        "detail": "nutrition_extractor.utils.label_map_util",
        "documentation": {}
    },
    {
        "label": "load_labelmap",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.label_map_util",
        "description": "nutrition_extractor.utils.label_map_util",
        "peekOfCode": "def load_labelmap(path):\n  \"\"\"Loads label map proto.\n  Args:\n    path: path to StringIntLabelMap proto text file.\n  Returns:\n    a StringIntLabelMapProto\n  \"\"\"\n  with tf.gfile.GFile(path, 'r') as fid:\n    label_map_string = fid.read()\n    label_map = string_int_label_map_pb2.StringIntLabelMap()",
        "detail": "nutrition_extractor.utils.label_map_util",
        "documentation": {}
    },
    {
        "label": "get_label_map_dict",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.label_map_util",
        "description": "nutrition_extractor.utils.label_map_util",
        "peekOfCode": "def get_label_map_dict(label_map_path, use_display_name=False):\n  \"\"\"Reads a label map and returns a dictionary of label names to id.\n  Args:\n    label_map_path: path to label_map.\n    use_display_name: whether to use the label map items' display names as keys.\n  Returns:\n    A dictionary mapping label names to id.\n  \"\"\"\n  label_map = load_labelmap(label_map_path)\n  label_map_dict = {}",
        "detail": "nutrition_extractor.utils.label_map_util",
        "documentation": {}
    },
    {
        "label": "create_category_index_from_labelmap",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.label_map_util",
        "description": "nutrition_extractor.utils.label_map_util",
        "peekOfCode": "def create_category_index_from_labelmap(label_map_path):\n  \"\"\"Reads a label map and returns a category index.\n  Args:\n    label_map_path: Path to `StringIntLabelMap` proto text file.\n  Returns:\n    A category index, which is a dictionary that maps integer ids to dicts\n    containing categories, e.g.\n    {1: {'id': 1, 'name': 'dog'}, 2: {'id': 2, 'name': 'cat'}, ...}\n  \"\"\"\n  label_map = load_labelmap(label_map_path)",
        "detail": "nutrition_extractor.utils.label_map_util",
        "documentation": {}
    },
    {
        "label": "create_class_agnostic_category_index",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.label_map_util",
        "description": "nutrition_extractor.utils.label_map_util",
        "peekOfCode": "def create_class_agnostic_category_index():\n  \"\"\"Creates a category index with a single `object` class.\"\"\"\n  return {1: {'id': 1, 'name': 'object'}}",
        "detail": "nutrition_extractor.utils.label_map_util",
        "documentation": {}
    },
    {
        "label": "save_image_array_as_png",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def save_image_array_as_png(image, output_path):\n  \"\"\"Saves an image (represented as a numpy array) to PNG.\n  Args:\n    image: a numpy array with shape [height, width, 3].\n    output_path: path to which image should be written.\n  \"\"\"\n  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n  with tf.gfile.Open(output_path, 'w') as fid:\n    image_pil.save(fid, 'PNG')\ndef encode_image_array_as_png_str(image):",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "encode_image_array_as_png_str",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def encode_image_array_as_png_str(image):\n  \"\"\"Encodes a numpy array into a PNG string.\n  Args:\n    image: a numpy array with shape [height, width, 3].\n  Returns:\n    PNG encoded image string.\n  \"\"\"\n  image_pil = Image.fromarray(np.uint8(image))\n  output = six.BytesIO()\n  image_pil.save(output, format='PNG')",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "draw_bounding_box_on_image_array",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def draw_bounding_box_on_image_array(image,\n                                     ymin,\n                                     xmin,\n                                     ymax,\n                                     xmax,\n                                     color='red',\n                                     thickness=4,\n                                     display_str_list=(),\n                                     use_normalized_coordinates=True):\n  \"\"\"Adds a bounding box to an image (numpy array).",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "draw_bounding_box_on_image",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def draw_bounding_box_on_image(image,\n                               ymin,\n                               xmin,\n                               ymax,\n                               xmax,\n                               color='red',\n                               thickness=4,\n                               display_str_list=(),\n                               use_normalized_coordinates=True):\n  \"\"\"Adds a bounding box to an image.",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "draw_bounding_boxes_on_image_array",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def draw_bounding_boxes_on_image_array(image,\n                                       boxes,\n                                       color='red',\n                                       thickness=4,\n                                       display_str_list_list=()):\n  \"\"\"Draws bounding boxes on image (numpy array).\n  Args:\n    image: a numpy array object.\n    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n           The coordinates are in normalized format between [0, 1].",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "draw_bounding_boxes_on_image",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def draw_bounding_boxes_on_image(image,\n                                 boxes,\n                                 color='red',\n                                 thickness=4,\n                                 display_str_list_list=()):\n  \"\"\"Draws bounding boxes on image.\n  Args:\n    image: a PIL.Image object.\n    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n           The coordinates are in normalized format between [0, 1].",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "draw_bounding_boxes_on_image_tensors",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def draw_bounding_boxes_on_image_tensors(images,\n                                         boxes,\n                                         classes,\n                                         scores,\n                                         category_index,\n                                         instance_masks=None,\n                                         keypoints=None,\n                                         max_boxes_to_draw=20,\n                                         min_score_thresh=0.2):\n  \"\"\"Draws bounding boxes, masks, and keypoints on batch of image tensors.",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "draw_side_by_side_evaluation_image",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def draw_side_by_side_evaluation_image(eval_dict,\n                                       category_index,\n                                       max_boxes_to_draw=20,\n                                       min_score_thresh=0.2):\n  \"\"\"Creates a side-by-side image with detections and groundtruth.\n  Bounding boxes (and instance masks, if available) are visualized on both\n  subimages.\n  Args:\n    eval_dict: The evaluation dictionary returned by\n      eval_util.result_dict_for_single_example().",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "draw_keypoints_on_image_array",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def draw_keypoints_on_image_array(image,\n                                  keypoints,\n                                  color='red',\n                                  radius=2,\n                                  use_normalized_coordinates=True):\n  \"\"\"Draws keypoints on an image (numpy array).\n  Args:\n    image: a numpy array with shape [height, width, 3].\n    keypoints: a numpy array with shape [num_keypoints, 2].\n    color: color to draw the keypoints with. Default is red.",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "draw_keypoints_on_image",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def draw_keypoints_on_image(image,\n                            keypoints,\n                            color='red',\n                            radius=2,\n                            use_normalized_coordinates=True):\n  \"\"\"Draws keypoints on an image.\n  Args:\n    image: a PIL.Image object.\n    keypoints: a numpy array with shape [num_keypoints, 2].\n    color: color to draw the keypoints with. Default is red.",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "draw_mask_on_image_array",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def draw_mask_on_image_array(image, mask, color='red', alpha=0.4):\n  \"\"\"Draws mask on an image.\n  Args:\n    image: uint8 numpy array with shape (img_height, img_height, 3)\n    mask: a uint8 numpy array of shape (img_height, img_height) with\n      values between either 0 or 1.\n    color: color to draw the keypoints with. Default is red.\n    alpha: transparency value between 0 and 1. (default: 0.4)\n  Raises:\n    ValueError: On incorrect data type for image or masks.",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "visualize_boxes_and_labels_on_image_array",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def visualize_boxes_and_labels_on_image_array(\n    image,\n    boxes,\n    classes,\n    scores,\n    category_index,\n    instance_masks=None,\n    instance_boundaries=None,\n    keypoints=None,\n    use_normalized_coordinates=False,",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "add_cdf_image_summary",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def add_cdf_image_summary(values, name):\n  \"\"\"Adds a tf.summary.image for a CDF plot of the values.\n  Normalizes `values` such that they sum to 1, plots the cumulative distribution\n  function and creates a tf image summary.\n  Args:\n    values: a 1-D float32 tensor containing the values.\n    name: name for the image summary.\n  \"\"\"\n  def cdf_plot(values):\n    \"\"\"Numpy function to plot CDF.\"\"\"",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "add_hist_image_summary",
        "kind": 2,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "def add_hist_image_summary(values, bins, name):\n  \"\"\"Adds a tf.summary.image for a histogram plot of the values.\n  Plots the histogram of values and creates a tf image summary.\n  Args:\n    values: a 1-D float32 tensor containing the values.\n    bins: bin edges which will be directly passed to np.histogram.\n    name: name for the image summary.\n  \"\"\"\n  def hist_plot(values, bins):\n    \"\"\"Numpy function to plot hist.\"\"\"",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "_TITLE_LEFT_MARGIN",
        "kind": 5,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "_TITLE_LEFT_MARGIN = 10\n_TITLE_TOP_MARGIN = 10\nSTANDARD_COLORS = [\n    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "_TITLE_TOP_MARGIN",
        "kind": 5,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "_TITLE_TOP_MARGIN = 10\nSTANDARD_COLORS = [\n    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "STANDARD_COLORS",
        "kind": 5,
        "importPath": "nutrition_extractor.utils.visualization_utils",
        "description": "nutrition_extractor.utils.visualization_utils",
        "peekOfCode": "STANDARD_COLORS = [\n    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',",
        "detail": "nutrition_extractor.utils.visualization_utils",
        "documentation": {}
    },
    {
        "label": "crop",
        "kind": 2,
        "importPath": "nutrition_extractor.crop",
        "description": "nutrition_extractor.crop",
        "peekOfCode": "def crop(image_obj, coords, saved_location, extend_ratio=0, SAVE=False):\n    \"\"\"\n    @param image_path: The image object to be cropped\n    @param coords: A tuple of x/y coordinates (x1, y1, x2, y2)\n    @param saved_location: Path to save the cropped image\n    @param extend_ratio: The value by which the bounding boxes to be extended to accomodate the text that has been cut\n    @param SAVE: whether to save the cropped image or not\n    \"\"\"\n    nx = image_obj.shape[1]\n    ny = image_obj.shape[0]",
        "detail": "nutrition_extractor.crop",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "nutrition_extractor.crop",
        "description": "nutrition_extractor.crop",
        "peekOfCode": "def main():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"-i\", \"--image\", required=True, help=\"path to the input image\")\n    ap.add_argument(\"-c\", \"--coords\", nargs=\"+\", type = int, required=True, help=\"path to the input image\")\n    args = ap.parse_args()\n    coords = tuple(args.coords)\n    saved_location = './'\n    image = cv2.imread(args.image)\n    crop_img(image, coords, saved_location)\nif __name__ == '__main__':",
        "detail": "nutrition_extractor.crop",
        "documentation": {}
    },
    {
        "label": "NutritionTableDetector",
        "kind": 6,
        "importPath": "nutrition_extractor.detect_table_class",
        "description": "nutrition_extractor.detect_table_class",
        "peekOfCode": "class NutritionTableDetector(object):\n    def __init__(self):\n        PATH_TO_MODEL = 'data/frozen_inference_graph.pb'\n        self.detection_graph = tf.Graph()\n        with self.detection_graph.as_default():\n            od_graph_def = tf.GraphDef()\n            # Works up to here.\n            with tf.gfile.GFile(PATH_TO_MODEL, 'rb') as fid:\n                serialized_graph = fid.read()\n                od_graph_def.ParseFromString(serialized_graph)",
        "detail": "nutrition_extractor.detect_table_class",
        "documentation": {}
    },
    {
        "label": "detect_all",
        "kind": 2,
        "importPath": "nutrition_extractor.detection",
        "description": "nutrition_extractor.detection",
        "peekOfCode": "def detect_all(img_path, debug):\n    dict1=detect(img_path, debug,True)\n    print(\"first scan :\",dict1)\n    dict2=detect(\"./data/result/second-input.jpg\", debug,False)\n    print(\"second scan :\",dict2)\n    print(\"final result :\",{**dict2,**dict1})\n    return {**dict2,**dict1}\ndef load_model():\n    \"\"\"\n    load trained weights for the model",
        "detail": "nutrition_extractor.detection",
        "documentation": {}
    },
    {
        "label": "load_model",
        "kind": 2,
        "importPath": "nutrition_extractor.detection",
        "description": "nutrition_extractor.detection",
        "peekOfCode": "def load_model():\n    \"\"\"\n    load trained weights for the model\n    \"\"\"    \n    global obj,obj2\n    obj = NutritionTableDetector()\n    obj2 = NutritionTableDetector()\n    print (\"Weights Loaded!\")\ndef detect(img_path, debug,firstCall=False):\n    \"\"\"",
        "detail": "nutrition_extractor.detection",
        "documentation": {}
    },
    {
        "label": "detect",
        "kind": 2,
        "importPath": "nutrition_extractor.detection",
        "description": "nutrition_extractor.detection",
        "peekOfCode": "def detect(img_path, debug,firstCall=False):\n    \"\"\"\n    @param img_path: Pathto the image for which labels to be extracted\n    \"\"\"\n    #Start the time\n    start_time = time.time()\n    #Make the table detector class and predict the score\n    image = cv2.imread(img_path)\n    boxes, scores, classes, num  = obj.get_classification(image)\n    #Get the dimensions of the image",
        "detail": "nutrition_extractor.detection",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "nutrition_extractor.detection",
        "description": "nutrition_extractor.detection",
        "peekOfCode": "def main():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"-i\", \"--image\", required=True, help=\"path to the input image\")\n    ap.add_argument(\"-d\", \"--debug\", action='store_true', help=\"print some debug info\")\n    args = ap.parse_args()\n    if args.debug:\n# get the current working directory\n        current_directory = os.getcwd()\n# specify the relative path of the folder to be emptied\n        folder_name = 'data/result'",
        "detail": "nutrition_extractor.detection",
        "documentation": {}
    },
    {
        "label": "FuzzyDict",
        "kind": 6,
        "importPath": "nutrition_extractor.fuzzydict",
        "description": "nutrition_extractor.fuzzydict",
        "peekOfCode": "class FuzzyDict(dict):\n    \"Provides a dictionary that performs fuzzy lookup\"\n    def __init__(self, items = None, cutoff = .6):\n        \"\"\"Construct a new FuzzyDict instance\n        items is an dictionary to copy items from (optional)\n        cutoff is the match ratio below which mathes should not be considered\n        cutoff needs to be a float between 0 and 1 (where zero is no match\n        and 1 is a perfect match)\"\"\"\n        super(FuzzyDict, self).__init__()\n        if items:",
        "detail": "nutrition_extractor.fuzzydict",
        "documentation": {}
    },
    {
        "label": "__revision__",
        "kind": 5,
        "importPath": "nutrition_extractor.fuzzydict",
        "description": "nutrition_extractor.fuzzydict",
        "peekOfCode": "__revision__ = \"$Rev$\"\nimport difflib\nclass FuzzyDict(dict):\n    \"Provides a dictionary that performs fuzzy lookup\"\n    def __init__(self, items = None, cutoff = .6):\n        \"\"\"Construct a new FuzzyDict instance\n        items is an dictionary to copy items from (optional)\n        cutoff is the match ratio below which mathes should not be considered\n        cutoff needs to be a float between 0 and 1 (where zero is no match\n        and 1 is a perfect match)\"\"\"",
        "detail": "nutrition_extractor.fuzzydict",
        "documentation": {}
    },
    {
        "label": "make_list",
        "kind": 2,
        "importPath": "nutrition_extractor.nutrient_list",
        "description": "nutrition_extractor.nutrient_list",
        "peekOfCode": "def make_list(fname):\n    '''\n    @param fname: path to the dictionary\n    '''\n    with open(fname) as f:\n        content = f.readlines()\n    # you may also want to remove whitespace characters like `\\n` at the end of each line\n    content = [x.strip() for x in content]\n    # return tuple(open(fname, 'r'))\n    return tuple(content);",
        "detail": "nutrition_extractor.nutrient_list",
        "documentation": {}
    },
    {
        "label": "make_fuzdict",
        "kind": 2,
        "importPath": "nutrition_extractor.nutrient_list",
        "description": "nutrition_extractor.nutrient_list",
        "peekOfCode": "def make_fuzdict(fname):\n     '''\n     @param fname: path to the dictionary\n     '''\n     with open(fname) as f:\n         content = f.readlines()\n     # you may also want to remove whitespace characters like `\\n` at the end of each line\n     content = [x.strip() for x in content]\n     fd = FuzzyDict({}, cutoff = .55)\n     for y in content:",
        "detail": "nutrition_extractor.nutrient_list",
        "documentation": {}
    },
    {
        "label": "preprocess_for_ocr",
        "kind": 2,
        "importPath": "nutrition_extractor.process",
        "description": "nutrition_extractor.process",
        "peekOfCode": "def preprocess_for_ocr(img, enhance=1):\n    \"\"\"\n    @param img: image to which the pre-processing steps being applied\n    \"\"\"\n    if enhance > 1:\n        img = Image.fromarray(img)\n        contrast = ImageEnhance.Contrast(img)\n        img = contrast.enhance(enhance)\n        img = np.asarray(img)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)",
        "detail": "nutrition_extractor.process",
        "documentation": {}
    },
    {
        "label": "ocr",
        "kind": 2,
        "importPath": "nutrition_extractor.process",
        "description": "nutrition_extractor.process",
        "peekOfCode": "def ocr(img, oem=1, psm=3):\n    \"\"\"\n    @param img: The image to be OCR'd\n    @param oem: for specifying the type of Tesseract engine( default=1 for LSTM OCR Engine)\n    \"\"\"\n    config = ('-l eng --oem {oem} --psm {psm}'.format(oem=oem,psm=psm))\n    # config = ('-l eng --tessdata-dir \"/usr/share/tesseract-ocr/tessdata\" --oem {oem} -- psm {psm}'.format(oem=oem,psm=psm))\n    try:\n        img = Image.fromarray(img)\n        text = pytesseract.image_to_string(img, config=config)",
        "detail": "nutrition_extractor.process",
        "documentation": {}
    },
    {
        "label": "change_to_g",
        "kind": 2,
        "importPath": "nutrition_extractor.regex",
        "description": "nutrition_extractor.regex",
        "peekOfCode": "def change_to_g(text):\n    search_ln = re.search(\"\\d\\s|\\d$\", text)\n    if search_ln and search_ln.group().strip() == \"9\":\n        index = search_ln.span()[0]\n        text = text[:index] +\"g\"+ text[index+1:]\n    search_lnq = re.search(\"\\dmq\\s|\\dmq$\", text)\n    if search_lnq:\n        index = search_lnq.span()[0] +2\n        text = text[:index] +\"g\"+ text[index+1:]\n    return text",
        "detail": "nutrition_extractor.regex",
        "documentation": {}
    },
    {
        "label": "clean_string",
        "kind": 2,
        "importPath": "nutrition_extractor.regex",
        "description": "nutrition_extractor.regex",
        "peekOfCode": "def clean_string(string):\n    pattern = \"[\\|\\*\\_\\'\\—\\-\\{}]\".format('\"')\n    text = re.sub(pattern, \"\", string)\n    text = re.sub(\" I \", \" / \", text)\n    text = re.sub(\"^I \", \"\", text)\n    text = re.sub(\"Omg\", \"0mg\", text)\n    text = re.sub(\"Og\", \"0g\", text)\n    text = re.sub('(?<=\\d) (?=\\w)', '', text)\n    text = change_to_g(text)\n    text = text.strip()",
        "detail": "nutrition_extractor.regex",
        "documentation": {}
    },
    {
        "label": "check_for_label",
        "kind": 2,
        "importPath": "nutrition_extractor.regex",
        "description": "nutrition_extractor.regex",
        "peekOfCode": "def check_for_label(text, words):\n    # text = text.lower()\n    for i in range(len(text)):\n        if any(text[i:].startswith(word) for word in words):\n            return True\n    return False\ndef fuz_check_for_label(text, fuzdict, debug):\n    if debug:\n        print(\"fuz_check_for_label : {}\".format(text))\n    # text = text.lower()",
        "detail": "nutrition_extractor.regex",
        "documentation": {}
    },
    {
        "label": "fuz_check_for_label",
        "kind": 2,
        "importPath": "nutrition_extractor.regex",
        "description": "nutrition_extractor.regex",
        "peekOfCode": "def fuz_check_for_label(text, fuzdict, debug):\n    if debug:\n        print(\"fuz_check_for_label : {}\".format(text))\n    # text = text.lower()\n    text = clean_string(text)\n    if fuzdict.__contains__(text):\n        return True\n    else:\n        if fuzdict.__contains__(re.split('[/|I]',text)[0]):\n            return True",
        "detail": "nutrition_extractor.regex",
        "documentation": {}
    },
    {
        "label": "get_label_from_string",
        "kind": 2,
        "importPath": "nutrition_extractor.regex",
        "description": "nutrition_extractor.regex",
        "peekOfCode": "def get_label_from_string(string):\n    label_arr = re.findall(\"([A-Z][a-zA-Z]*)\", string)\n    label_name = \"\"\n    label_value = \"\"\n    if len(label_arr) == 0:\n        label_name = \"|\"+string+'|'\n    elif len(label_arr) == 1:\n        label_name = label_arr[0]\n    else:\n        label_name = label_arr[0] + ' ' + label_arr[1]",
        "detail": "nutrition_extractor.regex",
        "documentation": {}
    },
    {
        "label": "get_fuz_label_from_string",
        "kind": 2,
        "importPath": "nutrition_extractor.regex",
        "description": "nutrition_extractor.regex",
        "peekOfCode": "def get_fuz_label_from_string(string, fuzdict, debug):\n     string = clean_string(string)\n     if debug:\n         print(\"get_fuz_label_from_string : {}\".format(string))\n     label_arr = re.findall(\"([a-zA-Z]+)\", string)\n     label_name = \"\"\n     label_value = \"\"\n     if fuzdict.__contains__(string):\n         label_name = fuzdict[string]\n     else:",
        "detail": "nutrition_extractor.regex",
        "documentation": {}
    },
    {
        "label": "separate_unit",
        "kind": 2,
        "importPath": "nutrition_extractor.regex",
        "description": "nutrition_extractor.regex",
        "peekOfCode": "def separate_unit(string):\n    r1 = re.compile(\"(\\d+[\\.\\,\\']?\\d*)([a-zA-Z]+)\")\n    m1 = r1.match(string)\n    r2 = re.compile(\"(\\d+[\\.\\,\\']?\\d*)\")\n    m2 = r2.match(string)\n    if m1:\n       return (float(m1.group(1).replace(',','.').replace(\"'\",'.')), m1.group(2))\n    elif m2:\n       return (float(m2.group(1).replace(',','.').replace(\"'\",'.')))\n    else:",
        "detail": "nutrition_extractor.regex",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "nutrition_extractor.regex",
        "description": "nutrition_extractor.regex",
        "peekOfCode": "def main():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"-s\", \"--string\", required=True, help=\"Enter the string to be cleaned\")\n    ap.add_argument(\"-f\", \"--flag\", required=True, help=\"Get which function ot call\")\n    args = ap.parse_args()\n    FLAG = int(args.flag)\n    if FLAG == 0:\n        print('Input: '+ args.string)\n        print('Output: ' + clean_string(args.string))\n    elif FLAG == 1:",
        "detail": "nutrition_extractor.regex",
        "documentation": {}
    },
    {
        "label": "get_filename",
        "kind": 2,
        "importPath": "nutrition_extractor.resize",
        "description": "nutrition_extractor.resize",
        "peekOfCode": "def get_filename(file):\n    name_list = filename.split(\"/\")\n    name = name_list[-1].split(\".\")\n    return name[0]\ndef resize(filename, nx, ny):\n    imagename = get_filename(filename)\n    img = im.resize((int(nx), int(ny)), Image.ANTIALIAS)\n    img.save(\"test_images/{}.jpg\".format(imagename), optimize=True, quality=95)\ncount = 0\npath = 'test_images/'",
        "detail": "nutrition_extractor.resize",
        "documentation": {}
    },
    {
        "label": "resize",
        "kind": 2,
        "importPath": "nutrition_extractor.resize",
        "description": "nutrition_extractor.resize",
        "peekOfCode": "def resize(filename, nx, ny):\n    imagename = get_filename(filename)\n    img = im.resize((int(nx), int(ny)), Image.ANTIALIAS)\n    img.save(\"test_images/{}.jpg\".format(imagename), optimize=True, quality=95)\ncount = 0\npath = 'test_images/'\nfor filename in glob.glob(os.path.join(path, '*.jpg')):\n    im = Image.open(filename)\n    nx, ny = im.size\n    if(nx >= ny):",
        "detail": "nutrition_extractor.resize",
        "documentation": {}
    },
    {
        "label": "count",
        "kind": 5,
        "importPath": "nutrition_extractor.resize",
        "description": "nutrition_extractor.resize",
        "peekOfCode": "count = 0\npath = 'test_images/'\nfor filename in glob.glob(os.path.join(path, '*.jpg')):\n    im = Image.open(filename)\n    nx, ny = im.size\n    if(nx >= ny):\n        new_nx = 1000\n        ratio = new_nx / nx\n        new_ny = ratio * ny \n        resize(filename, new_nx, new_ny)",
        "detail": "nutrition_extractor.resize",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "nutrition_extractor.resize",
        "description": "nutrition_extractor.resize",
        "peekOfCode": "path = 'test_images/'\nfor filename in glob.glob(os.path.join(path, '*.jpg')):\n    im = Image.open(filename)\n    nx, ny = im.size\n    if(nx >= ny):\n        new_nx = 1000\n        ratio = new_nx / nx\n        new_ny = ratio * ny \n        resize(filename, new_nx, new_ny)\n    else:",
        "detail": "nutrition_extractor.resize",
        "documentation": {}
    },
    {
        "label": "string_type",
        "kind": 2,
        "importPath": "nutrition_extractor.spacial_map",
        "description": "nutrition_extractor.spacial_map",
        "peekOfCode": "def string_type(string):\n    \"\"\"\n    @param string: Type of the string to be checked\n        0: both name and value\n        1: only the value\n        2: only the name\n    \"\"\"\n    if any(char.isdigit() for char in string): \n        if re.search(r'\\D{3,}\\s', string):\n            return 0",
        "detail": "nutrition_extractor.spacial_map",
        "documentation": {}
    },
    {
        "label": "position_definer",
        "kind": 2,
        "importPath": "nutrition_extractor.spacial_map",
        "description": "nutrition_extractor.spacial_map",
        "peekOfCode": "def position_definer(center_y, ymin, ymax):\n    \"\"\"\n    @param center_y: y coordinate of the search box\n    @param ymin: minimum y coordinate of the box to be tested for\n    @param ymax: maximum y coordinate of the box to be tested for\n    \"\"\"\n    return ymin < center_y < ymax\nif __name__ == '__main__':\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"-s\", \"--string\", required=True, help=\"string to be checked\")",
        "detail": "nutrition_extractor.spacial_map",
        "documentation": {}
    },
    {
        "label": "get_deletes_list",
        "kind": 2,
        "importPath": "nutrition_extractor.symspell",
        "description": "nutrition_extractor.symspell",
        "peekOfCode": "def get_deletes_list(w):\n    '''given a word, derive strings with up to max_edit_distance characters\n       deleted'''\n    deletes = []\n    queue = [w]\n    for d in range(max_edit_distance):\n        temp_queue = []\n        for word in queue:\n            if len(word)>1:\n                for c in range(len(word)):  # character index",
        "detail": "nutrition_extractor.symspell",
        "documentation": {}
    },
    {
        "label": "create_dictionary_entry",
        "kind": 2,
        "importPath": "nutrition_extractor.symspell",
        "description": "nutrition_extractor.symspell",
        "peekOfCode": "def create_dictionary_entry(w):\n    '''add word and its derived deletions to dictionary'''\n    # check if word is already in dictionary\n    # dictionary entries are in the form: (list of suggested corrections,\n    # frequency of word in corpus)\n    global longest_word_length\n    new_real_word_added = False\n    if w in dictionary:\n        # increment count of word in corpus\n        dictionary[w] = (dictionary[w][0], dictionary[w][1] + 1)  ",
        "detail": "nutrition_extractor.symspell",
        "documentation": {}
    },
    {
        "label": "create_dictionary",
        "kind": 2,
        "importPath": "nutrition_extractor.symspell",
        "description": "nutrition_extractor.symspell",
        "peekOfCode": "def create_dictionary(fname):\n    total_word_count = 0\n    unique_word_count = 0\n    with open(fname) as file:\n        print (\"Creating dictionary...\"     )\n        for line in file:\n            # separate by words by non-alphabetical characters      \n            words = re.findall('[a-z]+', line.lower())  \n            for word in words:\n                total_word_count += 1",
        "detail": "nutrition_extractor.symspell",
        "documentation": {}
    },
    {
        "label": "dameraulevenshtein",
        "kind": 2,
        "importPath": "nutrition_extractor.symspell",
        "description": "nutrition_extractor.symspell",
        "peekOfCode": "def dameraulevenshtein(seq1, seq2):\n    \"\"\"Calculate the Damerau-Levenshtein distance between sequences.\n    This method has not been modified from the original.\n    Source: http://mwh.geek.nz/2009/04/26/python-damerau-levenshtein-distance/\n    This distance is the number of additions, deletions, substitutions,\n    and transpositions needed to transform the first sequence into the\n    second. Although generally used with strings, any sequences of\n    comparable objects will work.\n    Transpositions are exchanges of *consecutive* characters; all other\n    operations are self-explanatory.",
        "detail": "nutrition_extractor.symspell",
        "documentation": {}
    },
    {
        "label": "get_suggestions",
        "kind": 2,
        "importPath": "nutrition_extractor.symspell",
        "description": "nutrition_extractor.symspell",
        "peekOfCode": "def get_suggestions(string, silent=False):\n    '''return list of suggested corrections for potentially incorrectly\n       spelled word'''\n    if (len(string) - longest_word_length) > max_edit_distance:\n        if not silent:\n            print (\"no items in dictionary within maximum edit distance\")\n        return []\n    global verbose\n    suggest_dict = {}\n    min_suggest_len = float('inf')",
        "detail": "nutrition_extractor.symspell",
        "documentation": {}
    },
    {
        "label": "best_word",
        "kind": 2,
        "importPath": "nutrition_extractor.symspell",
        "description": "nutrition_extractor.symspell",
        "peekOfCode": "def best_word(s, silent=False):\n    try:\n        return get_suggestions(s, silent)[0]\n    except:\n        return None\ndef correct_document(fname, printlist=True):\n    # correct an entire document\n    with open(fname) as file:\n        doc_word_count = 0\n        corrected_word_count = 0",
        "detail": "nutrition_extractor.symspell",
        "documentation": {}
    },
    {
        "label": "correct_document",
        "kind": 2,
        "importPath": "nutrition_extractor.symspell",
        "description": "nutrition_extractor.symspell",
        "peekOfCode": "def correct_document(fname, printlist=True):\n    # correct an entire document\n    with open(fname) as file:\n        doc_word_count = 0\n        corrected_word_count = 0\n        unknown_word_count = 0\n        print (\"Finding misspelled words in your document...\" )\n        for i, line in enumerate(file):\n            # separate by words by non-alphabetical characters      \n            doc_words = re.findall('[a-z]+', line.lower())  ",
        "detail": "nutrition_extractor.symspell",
        "documentation": {}
    },
    {
        "label": "max_edit_distance",
        "kind": 5,
        "importPath": "nutrition_extractor.symspell",
        "description": "nutrition_extractor.symspell",
        "peekOfCode": "max_edit_distance = 3 \nverbose = 0\n# 0: top suggestion\n# 1: all suggestions of smallest edit distance\n# 2: all suggestions <= max_edit_distance (slower, no early termination)\ndictionary = {}\nlongest_word_length = 0\ndef get_deletes_list(w):\n    '''given a word, derive strings with up to max_edit_distance characters\n       deleted'''",
        "detail": "nutrition_extractor.symspell",
        "documentation": {}
    },
    {
        "label": "verbose",
        "kind": 5,
        "importPath": "nutrition_extractor.symspell",
        "description": "nutrition_extractor.symspell",
        "peekOfCode": "verbose = 0\n# 0: top suggestion\n# 1: all suggestions of smallest edit distance\n# 2: all suggestions <= max_edit_distance (slower, no early termination)\ndictionary = {}\nlongest_word_length = 0\ndef get_deletes_list(w):\n    '''given a word, derive strings with up to max_edit_distance characters\n       deleted'''\n    deletes = []",
        "detail": "nutrition_extractor.symspell",
        "documentation": {}
    },
    {
        "label": "dictionary",
        "kind": 5,
        "importPath": "nutrition_extractor.symspell",
        "description": "nutrition_extractor.symspell",
        "peekOfCode": "dictionary = {}\nlongest_word_length = 0\ndef get_deletes_list(w):\n    '''given a word, derive strings with up to max_edit_distance characters\n       deleted'''\n    deletes = []\n    queue = [w]\n    for d in range(max_edit_distance):\n        temp_queue = []\n        for word in queue:",
        "detail": "nutrition_extractor.symspell",
        "documentation": {}
    },
    {
        "label": "longest_word_length",
        "kind": 5,
        "importPath": "nutrition_extractor.symspell",
        "description": "nutrition_extractor.symspell",
        "peekOfCode": "longest_word_length = 0\ndef get_deletes_list(w):\n    '''given a word, derive strings with up to max_edit_distance characters\n       deleted'''\n    deletes = []\n    queue = [w]\n    for d in range(max_edit_distance):\n        temp_queue = []\n        for word in queue:\n            if len(word)>1:",
        "detail": "nutrition_extractor.symspell",
        "documentation": {}
    },
    {
        "label": "load_text_model",
        "kind": 2,
        "importPath": "nutrition_extractor.text_detection",
        "description": "nutrition_extractor.text_detection",
        "peekOfCode": "def load_text_model():\n    \"\"\"\n    load trained weights for the text detection model\n    \"\"\"\n    global obj\n    obj = NutritionTextDetector()\n    print (\"Text Weights Loaded!\")\ndef resize_im(im, scale, max_scale=None):\n    f = float(scale) / min(im.shape[0], im.shape[1])\n    if max_scale != None and f * max(im.shape[0], im.shape[1]) > max_scale:",
        "detail": "nutrition_extractor.text_detection",
        "documentation": {}
    },
    {
        "label": "resize_im",
        "kind": 2,
        "importPath": "nutrition_extractor.text_detection",
        "description": "nutrition_extractor.text_detection",
        "peekOfCode": "def resize_im(im, scale, max_scale=None):\n    f = float(scale) / min(im.shape[0], im.shape[1])\n    if max_scale != None and f * max(im.shape[0], im.shape[1]) > max_scale:\n        f = float(max_scale) / max(im.shape[0], im.shape[1])\n    return cv2.resize(im, None, None, fx=f, fy=f, interpolation=cv2.INTER_LINEAR), f\ndef draw_boxes(img, image_name, boxes, scale):\n    base_name = image_name.split('/')[-1]\n    with open('data/results/' + 'res_{}.txt'.format(base_name.split('.')[0]), 'w') as f:\n        for box in boxes:\n            if np.linalg.norm(box[0] - box[1]) < 5 or np.linalg.norm(box[3] - box[0]) < 5:",
        "detail": "nutrition_extractor.text_detection",
        "documentation": {}
    },
    {
        "label": "draw_boxes",
        "kind": 2,
        "importPath": "nutrition_extractor.text_detection",
        "description": "nutrition_extractor.text_detection",
        "peekOfCode": "def draw_boxes(img, image_name, boxes, scale):\n    base_name = image_name.split('/')[-1]\n    with open('data/results/' + 'res_{}.txt'.format(base_name.split('.')[0]), 'w') as f:\n        for box in boxes:\n            if np.linalg.norm(box[0] - box[1]) < 5 or np.linalg.norm(box[3] - box[0]) < 5:\n                continue\n            if box[8] >= 0.9:\n                color = (0, 255, 0)\n            elif box[8] >= 0.8:\n                color = (255, 0, 0)",
        "detail": "nutrition_extractor.text_detection",
        "documentation": {}
    },
    {
        "label": "return_blobs_tuple",
        "kind": 2,
        "importPath": "nutrition_extractor.text_detection",
        "description": "nutrition_extractor.text_detection",
        "peekOfCode": "def return_blobs_tuple(boxes, scale):\n    blob_list = []\n    for box in boxes:\n        min_x = min(int(box[0] / scale), int(box[2] / scale), int(box[4] / scale), int(box[6] / scale))\n        min_y = min(int(box[1] / scale), int(box[3] / scale), int(box[5] / scale), int(box[7] / scale))\n        max_x = max(int(box[0] / scale), int(box[2] / scale), int(box[4] / scale), int(box[6] / scale))\n        max_y = max(int(box[1] / scale), int(box[3] / scale), int(box[5] / scale), int(box[7] / scale)) \n        blob_list.append((min_x, min_y, max_x, max_y))\n    return(tuple(blob_list))\ndef text_detection(img):",
        "detail": "nutrition_extractor.text_detection",
        "documentation": {}
    },
    {
        "label": "text_detection",
        "kind": 2,
        "importPath": "nutrition_extractor.text_detection",
        "description": "nutrition_extractor.text_detection",
        "peekOfCode": "def text_detection(img):\n    # im_name = \"test_images/0044000030667_1.jpg\"\n    #print(('Demo for {:s}'.format(im_name)))\n    # img = cv2.imread(im_name)\n    img, scale = resize_im(img, scale=TextLineCfg.SCALE, max_scale=TextLineCfg.MAX_SCALE)\n    blobs, im_scales = _get_blobs(img, None)\n    if cfg.TEST.HAS_RPN:\n        im_blob = blobs['data']\n        blobs['im_info'] = np.array(\n            [[im_blob.shape[1], im_blob.shape[2], im_scales[0]]],",
        "detail": "nutrition_extractor.text_detection",
        "documentation": {}
    },
    {
        "label": "NutritionTextDetector",
        "kind": 6,
        "importPath": "nutrition_extractor.text_detection_class",
        "description": "nutrition_extractor.text_detection_class",
        "peekOfCode": "class NutritionTextDetector(object):\n    def __init__(self):\n        self.detection_graph = tf.Graph()\n        with self.detection_graph.as_default():\n            config = tf.ConfigProto(allow_soft_placement=True)\n            self.sess = tf.Session(config=config)\n            with gfile.FastGFile('data/ctpn.pb', 'rb') as f:\n                graph_def = tf.GraphDef()\n                graph_def.ParseFromString(f.read())\n                self.sess.graph.as_default()",
        "detail": "nutrition_extractor.text_detection_class",
        "documentation": {}
    },
    {
        "label": "BASE_DIR",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/2.0/howto/deployment/checklist/\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '-a&48ca=r!lz)c^b+k*rxpn%-z+(boe1+-zz7*a^8&fyh33q@-'\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\nALLOWED_HOSTS = ['*']\n# Application definition\nINSTALLED_APPS = [",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "SECRET_KEY",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "SECRET_KEY = '-a&48ca=r!lz)c^b+k*rxpn%-z+(boe1+-zz7*a^8&fyh33q@-'\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\nALLOWED_HOSTS = ['*']\n# Application definition\nINSTALLED_APPS = [\n    'api',\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "DEBUG",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "DEBUG = True\nALLOWED_HOSTS = ['*']\n# Application definition\nINSTALLED_APPS = [\n    'api',\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "ALLOWED_HOSTS",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "ALLOWED_HOSTS = ['*']\n# Application definition\nINSTALLED_APPS = [\n    'api',\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "INSTALLED_APPS",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "INSTALLED_APPS = [\n    'api',\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n]\nMIDDLEWARE = [",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "MIDDLEWARE",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "MIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n]\nROOT_URLCONF = 'off-nutrition-table-extractor.urls'",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "ROOT_URLCONF",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "ROOT_URLCONF = 'off-nutrition-table-extractor.urls'\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "TEMPLATES",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "TEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "WSGI_APPLICATION",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "WSGI_APPLICATION = 'off-nutrition-table-extractor.wsgi.application'\n# Database\n# https://docs.djangoproject.com/en/2.0/ref/settings/#databases\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),\n    }\n}\n# Password validation",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "DATABASES",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),\n    }\n}\n# Password validation\n# https://docs.djangoproject.com/en/2.0/ref/settings/#auth-password-validators\nAUTH_PASSWORD_VALIDATORS = [\n    {",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "AUTH_PASSWORD_VALIDATORS",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "AUTH_PASSWORD_VALIDATORS = [\n    {\n        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',\n    },",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "LANGUAGE_CODE",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "LANGUAGE_CODE = 'en-us'\nTIME_ZONE = 'UTC'\nUSE_I18N = True\nUSE_L10N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/2.0/howto/static-files/\nSTATIC_URL = '/static/'",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "TIME_ZONE = 'UTC'\nUSE_I18N = True\nUSE_L10N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/2.0/howto/static-files/\nSTATIC_URL = '/static/'",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "USE_I18N",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "USE_I18N = True\nUSE_L10N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/2.0/howto/static-files/\nSTATIC_URL = '/static/'",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "USE_L10N",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "USE_L10N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/2.0/howto/static-files/\nSTATIC_URL = '/static/'",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "USE_TZ",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "USE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/2.0/howto/static-files/\nSTATIC_URL = '/static/'",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "STATIC_URL",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.settings",
        "description": "off-nutrition-table-extractor.settings",
        "peekOfCode": "STATIC_URL = '/static/'",
        "detail": "off-nutrition-table-extractor.settings",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.urls",
        "description": "off-nutrition-table-extractor.urls",
        "peekOfCode": "urlpatterns = [\n    path('admin/', admin.site.urls),\n    path('', include('api.urls')),\n]",
        "detail": "off-nutrition-table-extractor.urls",
        "documentation": {}
    },
    {
        "label": "application",
        "kind": 5,
        "importPath": "off-nutrition-table-extractor.wsgi",
        "description": "off-nutrition-table-extractor.wsgi",
        "peekOfCode": "application = get_wsgi_application()",
        "detail": "off-nutrition-table-extractor.wsgi",
        "documentation": {}
    },
    {
        "label": "bin_dir",
        "kind": 5,
        "importPath": "venv.bin.activate_this",
        "description": "venv.bin.activate_this",
        "peekOfCode": "bin_dir = os.path.dirname(abs_file)\nbase = bin_dir[: -len(\"bin\") - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir] + os.environ.get(\"PATH\", \"\").split(os.pathsep))\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.10/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if \"\" else path)",
        "detail": "venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "base",
        "kind": 5,
        "importPath": "venv.bin.activate_this",
        "description": "venv.bin.activate_this",
        "peekOfCode": "base = bin_dir[: -len(\"bin\") - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir] + os.environ.get(\"PATH\", \"\").split(os.pathsep))\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.10/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if \"\" else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]",
        "detail": "venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"PATH\"]",
        "kind": 5,
        "importPath": "venv.bin.activate_this",
        "description": "venv.bin.activate_this",
        "peekOfCode": "os.environ[\"PATH\"] = os.pathsep.join([bin_dir] + os.environ.get(\"PATH\", \"\").split(os.pathsep))\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.10/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if \"\" else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"VIRTUAL_ENV\"]",
        "kind": 5,
        "importPath": "venv.bin.activate_this",
        "description": "venv.bin.activate_this",
        "peekOfCode": "os.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.10/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if \"\" else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "prev_length",
        "kind": 5,
        "importPath": "venv.bin.activate_this",
        "description": "venv.bin.activate_this",
        "peekOfCode": "prev_length = len(sys.path)\nfor lib in \"../lib/python3.10/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if \"\" else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.path[:]",
        "kind": 5,
        "importPath": "venv.bin.activate_this",
        "description": "venv.bin.activate_this",
        "peekOfCode": "sys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.real_prefix",
        "kind": 5,
        "importPath": "venv.bin.activate_this",
        "description": "venv.bin.activate_this",
        "peekOfCode": "sys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.prefix",
        "kind": 5,
        "importPath": "venv.bin.activate_this",
        "description": "venv.bin.activate_this",
        "peekOfCode": "sys.prefix = base",
        "detail": "venv.bin.activate_this",
        "documentation": {}
    }
]